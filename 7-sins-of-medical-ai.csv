Sin 1 - Blind Trust to AI Over-reliance on AI systems without adequate validation or verification can lead to incorrect or inappropriate decision making, that can even cause harm to humans.;comment;Sin 2 - Over-regulation (no guts, no glory) Excessive regulation could prevent innovation and progress, and limit the ability of researchers and developers to experiment and take risks with new AI technologies.;comment;Sin 3 - Robotizing and dehumanization AI systems that replace human interaction and compassion in the patient-doctor relationship can lead to a loss of empathy and decreased patient satisfaction.;comment;Sin 4 - Wrong targets in optimization AI systems that prioritize metrics that do not align with overall patient outcomes can result in suboptimal decision making.;comment;Sin 5 - Over-informing and false forecasting AI systems that generate too much information or provide false predictions can lead to confusion and decreased trust in the technology.;comment;Sin 6 - Application of a statistics statement to an individual case AI systems that rely solely on statistical models without considering individual patient circumstances can lead to incorrect or inappropriate decision making.;comment;Sin 7 - Self-reference (AI-based) monitoring AI systems that rely solely on themselves for evaluation, without independent oversight, can lead to a lack of accountability and decreased transparency in decision making.;comment;Do you work in or consider yourself an expert in any of these fields:;Country;Age range;Any other comments;Thank you! This survey is anonymous. To receive the results by email, please leave your email address here.;Creation date
Fully agree;Blind trust to AI concerns me greatly. I see it in many areas outside of medicine, in particular, with students in higher education who use AI to do work that they should be learning, and then lack the expertise to assess or validate the AI's output. In medicine, the consequences from this can be much more dire.;Neutral;I think regulation can prevent innovation, but I also think that regulation *should*, to some degree, limit risk-taking when it comes to AI.;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Research;Canada;20-39;;;3/18/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;40-59;;;3/18/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Management";USA;20-39;;;3/18/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Japan;40-59;;;3/18/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Japan;40-59;;;3/18/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Germany;20-39;;;3/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Germany;20-39;;;3/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Japan;20-39;;;3/15/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";China;20-39;;;3/14/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;20-39;;;3/13/25
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;;USA;40-59;;;3/12/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;20-39;;;3/12/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Japan;40-59;;;3/12/25
Fully agree;;Partly agree;;Fully agree;;Neutral;;Fully agree;;Partly disagree;;Fully agree;;;USA;40-59;;;3/11/25
Partly agree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Partly agree;;Partly agree;;"Artificial Intelligence; Information Technology; Research";USA;40-59;;;3/11/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;20-39;;;3/11/25
Fully agree;"Systems are built on data, and data are potentially biased (intentionally e.g. discrimination or unintentionally e.g. they didn't know better). Without adequate validation or verification, no results based on this data should be trusted. 
Further, current AI systems do not consider context and underdefined/abstract issues, potentially leading to misjudgments/ wrong suggestions. ";Neutral;Working within limitations drives creativity. At the same time, there could be exceptions for research similar to the fair-use doctrine that would allow more freedom for research innovation but would aim more to protect the public from potentially harmful commercial applications.;Fully agree;Dozens of studies have shown that human empathy and exchange improve well-being. ;Partly agree;Well, the question is always what are the underlying parameters systems and humans optimize for. Some doctors do not provide sufficient treatments to keep their regular patients. The same could happen to systems. The risk for AI systems increases the more this sector is privatized and disregulated. ;Neutral;"In both cases, this depends on the human-AI interaction paradigm behind. More information are good, as it allows the user to potentially identify wrong assumptions or reasons for a decision. Presneting it in a meaningful way that supports decision-making depends on the interaction design and the presentation of the right information in the right context at the right time. What 'right' means here is the objective of current research.  
Same for false predictions: If a model reaches a conclusion based on provided data (assuming the model is sufficiently trained and working), the result is, in the least amount of cases, 'correct'. Instead, it is based on assumption and (historical and contextual) data that result in a confidence level of correctness. Hence, professionals must be able to evaluate and verify the results based on the feedback of the system, as well as the input information themselves.. ";Fully agree;see my comments above;Fully agree;see my comments above;Research;France;20-39;;;3/11/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;20-39;;;3/11/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;40-59;;;3/11/25
Fully agree;"The word ""over-reliance"" automatically refers to the fact that something has been taken too far.";Fully agree;"Too many ""and"" statements in one sentence. I agree to some parts the sentence but not all. Could of course...";Partly agree;This depends in which circumstance it will be deployed. If a person would not have access to a medical expert vs at least they get some help from AI systems...they would still be happy to have any help regardless whether there is empathy or not.;Neutral;It is also currently so right now in the medical system. There will always be metrics ...even for overall patient outcomes can be measured (PROMs, PREMs);Fully agree;"Yes, if a system is ""bad"" it is indeed bad.";Fully agree;Yes, they need to take into account personal data to make any sense.;Partly agree;We can say the same about humans. 4 eyes are better than 2 ...;"Medicine; Information Technology; Research";Estonia;20-39;"This was a nice short survey but very oversimplified version of what an AI system could do or will do. It does not also see how many of the same ""Sins"" with AI are also issues with doctors/humans in general right now as well. It will come down to choosing the lesser or two evils at some point. In places and circumstances where access to medical care is scarce...AI is better then nothing. ";;3/10/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;40-59;;;3/10/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;20-39;;;3/10/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology";USA;40-59;;;3/10/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology";Indonesia;40-59;;;3/10/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";China;20-39;;;3/10/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";China;40-59;;;3/10/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Australia;20-39;;;3/10/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";New Zealand;40-59;;;3/10/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Canada;above 60;;;3/9/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Canada;20-39;;;3/9/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Management";Canada;40-59;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Decision-Making";Morocco;40-59;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Colombia;20-39;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Argentina;40-59;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Switzerland;20-39;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;40-59;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";UK;above 60;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";UK;20-39;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology";USA;40-59;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Canada;20-39;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology";USA;40-59;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;20-39;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Mexico;40-59;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Canada;20-39;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";USA;40-59;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;20-39;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;40-59;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Canada;20-39;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Chile;40-59;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Canada;40-59;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Argentina;40-59;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;I am a high-school student;Information Technology;USA;below 20;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Management";Mexico;20-39;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Brazil;20-39;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";USA;40-59;;;3/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Canada;20-39;;;3/6/25
Fully agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;Information Technology;USA;40-59;;;3/5/25
Fully agree;;Neutral;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Artificial Intelligence;Spain;above 60;;;3/5/25
Fully agree;;Fully agree;;Partly disagree;;Partly agree;;Partely agree;;Fully agree;;Fully agree;;;USA;20-39;;;3/4/25
Fully agree;;Partly agree;;Fully agree;;Partly agree;Depends how involved the human/researcher is involved in making decisions based on the AI system solution.;Fully agree;;Partly agree;;Fully agree;;;Canada;;;;3/4/25
Fully agree;;Partly agree;;Fully agree;;Partly agree;;Partly disagree;;Partly agree;;Fully agree;;"Medicine; Research";Canada;40-59;;vinod.chandran@uhn.ca;3/4/25
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Canada;20-39;;;3/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;USA;40-59;;;3/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Ghana;20-39;;;3/4/25
Fully agree;;Fully agree;;Neutral;;Fully agree;;Fully agree;;Fully disagree;;Fully agree;;"Medicine; Research; Management";Sweden;above 60;;joakim.dillner@ki.se;3/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research; Management";USA;40-59;;;3/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;USA;20-39;I am a medical student;;3/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;40-59;;;3/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research; Management";Poland;20-39;;;3/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Poland;40-59;;;3/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Switzerland;20-39;;;3/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Research; Management";Paraguay;40-59;;;3/4/25
Partly agree;;Partly disagree;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Partly agree;;Research;China;20-39;;zhoujia07@gmail.com;3/4/25
Fully disagree;;Fully agree;;Partly disagree;;Partly agree;;Partely agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Portugal ;40-59;;;3/3/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Egypt;20-39;;;3/3/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Research";Malaysia;20-39;;;3/3/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Indonesia;20-39;;;3/2/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology";China;20-39;;;3/1/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Australia;20-39;;;3/1/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Management";Ghana;40-59;;;3/1/25
Fully agree;;Partly agree;some regulation is necessary;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;USA;20-39;;;3/1/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;Singapor;20-39;;;2/28/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Japan;20-39;;;2/26/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Research; Management";Nigeria;above 60;;;2/24/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Pakistan;below 20;;;2/24/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research; Management";Indonesia;20-39;;;2/24/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";China;20-39;;;2/24/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Japan;below 20;;;2/21/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Research; Management";Australia;20-39;;;2/21/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;Bulgaria;below 20;;;2/19/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";China;20-39;;;2/19/25
Fully agree;This is astonishing to witness, in fact. ;Fully disagree;Regulation actually improves innovation. What it prevents is harm.;Partly agree;Some things can be automated, human interaction isn't always needed. Eg, appointment scheduling - this is something where perhaps the human interaction of a person calling you to schedule an appointment isn't necessary. Other times, human interaction should have no intrusion of AI at all.;Fully agree;"This is obvious, and shouldn't even be in question. Ai is trained around specific tasks and outputs; decisions are about peoples' values, rights, and best interests.";Fully agree;There is a lot of evidence for this one;Fully disagree;This is what AI models are intended to do, and that's fine. The problem is when they are assumed to do more. No AI system can compute every individual feature of a patient, and this displaces reliance on the human and their testimony as the relevant evidence.;Fully agree;Some automated aspects of monitoring can potentially be helpful (limited evidence on this), but zero independent oversight is just ludicrous.;"Medicine; Artificial Intelligence; Research";Australia;20-39;;;2/19/25
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";UK;40-59;;p.kostkova@ucl.ac.uk;2/18/25
Fully agree;Clinical validation is fundamental to verifying the AI model's performance in a healthcare scenario. This validation provides a further evaluation than the standard performance metric. Multi-center generalization, explainability, and fairness are different criteria taken into account by clinicians. ;Partly disagree;It depends on the nature of the regulation. A trade-off is needed. Regulation can provide benefits in training healthcare stakeholders. On the other hand, excessive regulation could discourage the adoption of this new technology.;Partly agree;Human interactions (patient-doctor relationships) cannot be replaced by human-robot interaction (HRI). HRI can be a tool for supporting this interaction with no intention of replacing it. ;Fully agree;To achieve this alignment a, clinical validation is needed. It should be embedded in the model deploying phase to refine preprocessing and model training according to clinician suggestions iteratively.;Fully agree;Model prediction should be always supervised by clinical. The developed model should answer the standard pattern discrimination question, pattern characterization, and localization. That's the reason why an interpretable model is needed in this context.;Partly agree;Latent variable should be considered in this context by AI model and by clinician.;Fully agree;a clinical oversight is always needed ;"Artificial Intelligence; Information Technology; Research";Italy;20-39;;luca.romeo@unimc.it;2/18/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Bulgaria;20-39;;;2/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Hungary;20-39;;;2/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";India;below 20;;;2/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Estonia;below 20;;;2/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Cyprus;above 60;;;2/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Decision-Making";United Arab Emirates;20-39;;;2/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;Sri Lanka;below 20;;;2/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research; Management";Myanmar;20-39;;;2/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Indonesia;20-39;;;2/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Decision-Making";Hong Kong;20-39;;;2/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Taiwan;20-39;;;2/17/25
Fully agree;;Partly agree;;Fully agree;From a patient point of view, I believe that the patient-doctor relationship (no robot) is important in patients' mental calmness;Partly agree;;Fully agree;As the AI's ability to predict disease, I believe it's becoming crucial for human doctors' ability to analyze patients' status and doubt AI's decision critically.;Fully disagree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";South Korea;20-39; ;twyoo99@gmail.com;2/16/25
Partly agree;Yes, but also depends on the stakes and the relative performance of AI system vs human decision maker.;Partly disagree;;Fully agree;And lower quality of care overall.;Fully agree;;Fully agree;They can also lead to over-diagnosis.;Partly agree;Yes, if used without proper human oversight and control.;Fully agree;;Artificial Intelligence;Australia;40-59;;;2/15/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Research; Management; Public Authority";Norway;20-39;;;2/15/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";Spain;20-39;;;2/15/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;South Africa;below 20;;;2/15/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;New Zealand;40-59;;;2/15/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";Moldova;20-39;;;2/15/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Lesotho;40-59;;;2/15/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Management";Albania;40-59;for low developed countrys this is a big chanc;;2/15/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;Estonia;20-39;;;2/15/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";Slovenia;20-39;really important!;;2/15/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Research; Management";Kazhakhstan;20-39;;;2/14/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Research; Public Authority";Cameroon;40-59;We need this urgenly, desperate of human peoeple;;2/14/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Artificial Intelligence;Algeria;below 20;;;2/14/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;South Africa;20-39;;;2/14/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Management;Uzbekistan;40-59;thank you very much - this is so important;;2/14/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Management";Cambodia;40-59;this AI gives us a big chance as we do not have manpower nor do we have enough medical education - we need it;;2/13/25
Neutral;there should be no AI whatsoever - should be banned from medicione;Neutral;We need full regulation and a stop of scientific research - it should be forbidden;Neutral;no robots will ever replace humans - this is nonsense;Neutral;what metrrics should this be - I do not understand!;Neutral;no one can be over-informed - nonsense;Neutral;all statistics has to be banned from the hospitals - we need a human docotr;Neutral;this is science-ficton;"Public Authority; Decision-Making";Belgium;above 60;;;2/13/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Management;Congo;40-59;;;2/13/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Egypt;20-39;it is good;;2/13/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology";Mexico;40-59;;;2/13/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Research; Management";Bangladesh;20-39;big chance for us is this AI;;2/13/25
Fully agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management; Decision-Making";USA;20-39;;;2/11/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Public Authority; Decision-Making";Phillippines;40-59;;;2/11/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Spain;40-59;;;2/11/25
Fully agree;;Fully disagree;we need full regulation - AI must be banned;Fully agree;robots should not have any opportunities;Neutral;I do not understand this question;Fully disagree;If we have ALL information we can have the best possible outpuit;Fully agree;no statistics;Fully agree;;Management;Brussels;above 60;;;2/11/25
Fully agree;;Fully agree;;Fully disagree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research; Management";USA;40-59;;;2/10/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;Thailand;20-39;;;2/7/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Denmark;40-59;;;2/7/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Management; Public Authority";Italy;20-39;;;2/7/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";China;20-39;;;2/7/25
Fully agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;Neutral;;Fully agree;;Medicine;USA;40-59;;;1/31/25
Partly agree;;Partly agree;;Partly agree;;Partly agree;;Partely agree;;Partly agree;;Partly agree;;"Medicine; Artificial Intelligence; Information Technology; Research";USA;40-59;The phrasing of the questions are quite leading such that the only reasonable answer is in one direction. Would recommend rephrasing.;;1/31/25
Fully agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";USA;40-59;;qinstat@gmail.com;1/30/25
Fully agree;AI should be fully proved to be non-harmful before large-scale usage;Partly agree;The research exploration should be flexible;Partly disagree;Advanced AI can have personality, and even better than ordinary humans;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";China;20-39;These opinions are very interesting! And my research experiences indeed have some concerns and thoughts on these. Looking forward to your research progress and further discussion!;zhen.chen@yale.edu;1/28/25
Fully agree;;Fully agree;;Partly agree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";USA;20-39;;stu.zojaji@gmail.com;1/28/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Jordan;20-39;;;1/28/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Iran;20-39;;;1/28/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Japan;20-39;;;1/28/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Philippines;20-39;;;1/28/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;Vietnam;20-39;;;1/27/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Management";Congo;40-59;all this AI is for us in Africa important!;;1/27/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Indonesia;20-39;Very important survey! Thank you very much!;;1/27/25
Neutral;Yes, it is possible depending to the system and the environment.;Neutral;yes, we will be outrun by technology anyway.;Neutral;It depends;Neutral;;Neutral;;Neutral;;Neutral;Maybe.;;Austria;20-39;;e12407817@student.tuwien.ac.at;1/27/25
Neutral;The risks of bias, lack of transparency, and unforeseen consequences are very real and must be taken seriously. Over-reliance without robust safeguards can lead to harmful outcome - but who to hell weill be able to verify and validate this overly complex AI systems ???;Partly disagree;while excessive regulation can hinder innovation, some level of regulation is necessary to ensure the responsible development and deployment of AI systems. The goal should be to find a balance that encourages innovation while mitigating the potential risks.;Neutral;;Neutral;;Neutral;;Neutral;;Neutral;;;USA;above 60;I am very unsure about this survey;;1/26/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Ethiopia;40-59;bigh chance of AI for our continent;;1/26/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Russia;20-39;;;1/26/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Bangladesh;40-59;lacking human personnel is a big problem - we have high expectations to AI medicine;;1/26/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Nigeria;below 20;We have no doctors here, so we urgently need AI as replacement for the missing doctors;;1/26/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology";Serbia;20-39;;;1/26/25
Partly disagree;Bcz most of the AI does't provide exact answer what we expect , instead it provide partial output or approximate result but not exact results , so i don't trust AI fully ;Partly disagree;We know that AI is so dangerous , Exclusive regulation and innovations will help us to limit the ability to extend to far , so we can use AI for necessary use , but not to experiment too deep . ;Partly agree;True , Ai don't have emotions to understand the feelings of the human , which is big issue .;Partly disagree;AI will understand most of the cases in terms of matrix , but at the same time it predicts some of the cases wrong , which is why we cant totally trust the AI in making decisions.;Fully agree;True;Fully agree;true;Partly agree;some times we have to consider other circumstances and other things into accountability , to make accurate predictions.;"Artificial Intelligence; Information Technology; Decision-Making";Austria;20-39;;e12307012@student.tuwien.ac.at;1/26/25
Fully agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Partly agree;;Artificial Intelligence;USA;20-39;;;1/25/25
Fully agree;;Partly agree;;Fully agree;;Neutral;;Fully agree;;Neutral;;Partly agree;;"Medicine; Artificial Intelligence";USA;20-39;;;1/25/25
Partly agree;;Partly disagree;I disagree, we should apply a correct way then using AI technologies can not limit the ability of researchers and developers to experiment and take risks.;Fully disagree;;Neutral;;Partly disagree;currently, AI results only as reference to support doctors make a final descision.;Partly disagree;;Fully disagree;;"Artificial Intelligence; Information Technology; Research";Ireland;20-39;;na.li@tudublin.ie;1/25/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Japan;20-39;;;1/25/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research; Decision-Making";Malaysia;20-39;;;1/25/25
Fully agree;;Partly agree;;Neutral;;Fully agree;;Neutral;;Partly agree;;Fully agree;;;Austria;20-39;;;1/24/25
Fully agree;;Partly agree;;Partly disagree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";India;20-39;;;1/24/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research; Management";Philippines;20-39;;;1/24/25
Fully agree;In my experience with current AI Tools, they have difficulties with more complicated tasks. With such tasks they can give guidance but I would not trust them.;Partly agree;;Partly disagree;As humans will still be involved in the process, I don't think we will loose empathy. Of course a reassuring doctor might have a positive effect that will be missed out on, but on the other hand a doctor might make the patient feel more uncomfortable.;Partly agree;;Partely agree;;Partly agree;I do agree but it may be possible to avoid this with the right training data and model;Fully agree;;Information Technology;Austria;20-39;;;1/23/25
Fully agree;;Fully agree;;Partly disagree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";India;20-39;;amulyaprasad1992@gmail.com;1/23/25
Fully agree;No AI or system should be blindly trusted... Unless it has been proven it's reliability and generalisation power;Partly agree;Over regulation can be counter productive and harmful in a similar manner than under regulation... Regulation should be adapted to the situation.;Partly agree;"We should avoid replacing... 
We should favour complementing... Save time so more time can be given to patient interaction ";Fully agree;Hence the importance of validation and certification by independent bodies...;Partely agree;"Too much information is not an issue if accurate
Inaccurate information can happen, although it should be be rare so the AI provides the means to better the performance of the clinician";Partly agree;In most case I would agree, but there are situation (simple ones) where AI may not be needed to improve patient diagnostics and management ;Neutral;If such system pass the validation criteria dictated by regulatory bodies ... ;"Artificial Intelligence; Information Technology; Research; Management";France;40-59;;benoit.huet@mediantechnologies.com;1/22/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Saudi Arabia;40-59;;;1/22/25
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";USA;above 60;;jhholmes@pennmedicine.upenn.edu;1/21/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Singapore;40-59;;;1/21/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Pakistan;40-59;;;1/21/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";China;40-59;;;1/21/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";South Korea;40-59;;;1/20/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Taiwan ;40-59;;;1/20/25
Neutral;There will not be a overreliance;Fully disagree;We need full regulation to stop this crazy scientists;Fully agree;this is a big danger;Fully agree;too much technology will loose the humanity;Fully agree;This is well know from the fiftees as information overload;Fully agree;a single patient cannot be described by pure statistics - humans are not numbers;Neutral;My fear here is that who should take over the oversight - is an oversight still possibel ?;"Medicine; Management; Public Authority";Belgium;40-59;;;1/20/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Public Authority;Nigeria;40-59;For us in Africa these new tools are a big chance, because we are so few peopl - we lack manpower;;1/20/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research; Management";Cyprus;40-59;;;1/20/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;South Korea;40-59;;;1/19/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Austria;below 20;;;1/19/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research; Management";Danmark;40-59;;;1/19/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Switzerland;20-39;;;1/19/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Serbia;40-59;;;1/19/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Management; Public Authority";Singapore;above 60;;;1/18/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;Australia;40-59;;;1/18/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;China;above 60;;;1/18/25
Partly agree;;Fully agree;;Partly disagree;;Partly disagree;;Partly disagree;;Partly disagree;;Neutral;;"Artificial Intelligence; Research";Germany;40-59;;;1/18/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Artificial Intelligence;Romania;above 60;;;1/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research; Management";Greece;40-59;;;1/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Jordan;40-59;;;1/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Turkey;20-39;;;1/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;South Korea;40-59;Excellent - and well done - thank you very much!;;1/17/25
Neutral;I am unsure if I understood the question correctly - who should verfify?;Neutral;We need regulation - otherwise development would be far to progressive;Neutral;this is not an inclusve question;Neutral;I do not understand this question - this is a far too complicated question to ask;Neutral;confusion is not defined;Neutral;highly theoretical;Neutral;but who should provide this oversight;;USA;40-59;The wording of this questionnaire is not inclusive, it is important to address always gender related aspects, particularly diverse, non-binary, bigender, agender, genderfluid, this is important and should always be acknowledged even if the authors think it is not necessary!;;1/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;this wonder AI is big chanc for Africa - we hav no peopel here;;Kenya;40-59;;;1/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;Colombia;20-39;;;1/17/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Israel;20-39;;;1/16/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Israel;20-39;;;1/16/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;India;20-39;;;1/16/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;Argentina;40-59;;;1/16/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research; Management";Vietnam;40-59;;;1/16/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";China;20-39;;;1/16/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research; Management";Japan;above 60;;;1/16/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Australia;20-39;;;1/16/25
Fully agree;;Neutral;This is very hard to even analyse - it is crucial to let everyone know, be completely transparent to whoever is involved about risks and benefits, which is what I have not been seeing as a normal practice in the medical field.;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;Ultimately humans need to be the decision makers ;"Management; Decision-Making";Austria;40-59;;jutta.jerlich@tuwien.ac.at;1/16/25
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Philippines;20-39;;jpaggarao@up.edu.ph;1/16/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Egypt;40-59;;;1/15/25
Fully agree;More than validation or verification - blind trust will make people lose the ability reflect on the outputs of the AI models and be critical about them.;Partly agree;I agree that imposing regulations on things that still do not exist can be harmful to innovation. However, there are some positive aspects on grounding the development of AI technologies on good, fair, and trustworthy practices.;Neutral;I recall a study where patients reported that they felt more empathy from a medical chatbot than actual doctors that seemed to be running from patient to patient. Maybe adding AI robots in the loop will create the opportunity for human doctors to become more accessible and have more time to interact with the patients.;Fully agree;This is a personal view, but I argue for human-centered and personalized AI technologies that focus on medical and patient needs instead of only reaching good scores.;Partely agree;The generated information must be adjusted to the user, his/her knowledge and skill.;Partly agree;;Partly agree;The ideal would be to have some sort of AI with human in the loop.;"Artificial Intelligence; Research";Portugal;20-39;;ana.c.fidalgo.barata@tecnico.ulisboa.pt;1/14/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Management; Decision-Making";UK;40-59;;;1/14/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Norway;20-39;;;1/14/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Tunisia;20-39;;;1/14/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology";Italy;40-59;;;1/14/25
Fully disagree;;Partly disagree;I partly agree that it will take it will limit some things, but overall disagree because researchers will always find a way and the benefits overtop the effort;Partly agree;Only if overused or used in the 'wrong' ocasion ;Neutral;;Partely agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Public Authority";Portugal;20-39;I work in a field related to AI but on the social end of things;;1/13/25
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;Japan;20-39;;;1/13/25
Fully agree;;Fully agree;We already see this now;Neutral;In many cases a timely appointment is more important than the emphatic interaction;Partly agree;;Partely agree;;Partly agree;This is not much different from an internet search that many patients already do ;Partly agree;;Research;Germany;40-59;;;1/12/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Decision-Making";South Korea;above 60;;;1/12/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Tanzania;40-59;Great ! AI will give us a lot of chances!;;1/12/25
Fully agree;;Fully agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Canada;40-59;;;1/12/25
Fully agree;;Partly agree;;Neutral;neutral because AI chatbots can be nowadays very empathic ;Partly agree;metrics should include patient outcomes ...;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Singapore;40-59;;andreeani@yahoo.com;1/11/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";Australia;40-59;;;1/11/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology";Japan;40-59;;;1/11/25
Fully agree;;Fully agree;;Partly disagree;;Neutral;;Fully agree;;Partly disagree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Portugal;40-59;;;1/11/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Poland;40-59;;;1/11/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;Nigeria;20-39;here we do not have trained peopel;;1/11/25
Fully agree;;Fully agree;absolutely agree !!!;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Algeria;40-59;;;1/11/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Switzerland;40-59;It is of utmost importance to stop this regulation madness - science is free and also AI research should be free;;1/11/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Taiwan;20-39;;;1/11/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Hungary;40-59;;;1/11/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology";Switzerland;20-39;;;1/11/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;Botswana;40-59;AI is a big chance for us all;;1/10/25
Neutral;The question is who should do this validation??;Fully disagree;No, No - we need full regulation - science must be guided by our value principles!;Fully agree;;Fully agree;;Fully agree;consequently we need regulation;Neutral;what do you mean here?;Fully agree;threrefore we need regulations;"Management; Public Authority; Decision-Making";Belgium;40-59;;;1/10/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Management;Nigeria;20-39;for Africa this AI is a big chance;;1/10/25
Fully agree;;Fully agree;;Partly agree;;Fully agree;;Partely agree;;Fully agree;;Partly agree;;"Artificial Intelligence; Research";Slovenia;40-59;;;1/9/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Morocco;40-59;I am not in Medicine or AI - but I think this is important;;1/9/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Algeria;40-59;very important - thank you for doing this!;;1/9/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;South Africa;20-39;;;1/9/25
Fully agree;;Fully disagree;we have to regulate, because otherwise scientists would do what they like - we have always to stay within our values;Neutral;I do not know what this question should indicate?;Neutral;I do not understand this question either;Fully agree;yes, that is right, because more information does not mean more knowledge - if I understood correctly;Neutral;I do not know what this should really mean - this question is not well phrased;Neutral;how can it be rely on themselves ? It seems fictional;"Management; Public Authority";Belgium;above 60;"The wording is sometimes questionnable; public available phrases should not use dubious words, this questionaire is not inclusvie and does not integrate non-binary aspects";;1/9/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Management";Vietnam;20-39;;;1/9/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Philippines;20-39;;;1/9/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Bangladesh;40-59;;;1/9/25
Fully disagree;;Fully agree;;Fully disagree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research; Decision-Making";Qatar;40-59;;rmt4003@qatar-med.cornell.edu;1/8/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Egypt;20-39;;;1/8/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology";Croatia;40-59;;;1/8/25
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research; Management; Decision-Making";Austria;40-59;;michael.grosinger@at.ibm.com;1/7/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Gabon;above 60;generally AI is for us important as we do not have humans enough here ;;1/7/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Bangladesh;above 60;We have to few human doctors - AI is a big chance for us;;1/7/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;Pakistan;40-59;Humble Sirs - very good;;1/7/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Portugal;40-59;;;1/7/25
Partly agree;;Partly disagree;;Neutral;;Fully disagree;;Partely agree;;Fully agree;;Fully agree;;"Information Technology; Research";Germany;40-59;;;1/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Management";Turkey;40-59;;;1/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Research; Management";Maroc;40-59;;;1/6/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology";Lebanon;40-59;;;1/6/25
Fully agree;;Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Artificial Intelligence;USA;40-59;;;1/5/25
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Partely agree;;Partly agree;;Fully agree;;;Austria;20-39;;davelooseluca@gmail.com;1/5/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Bulgaria;40-59;;;1/5/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Luxembourg;20-39;;;1/5/25
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";Italy ;40-59;;;1/4/25
Fully agree;;Partly disagree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research; Decision-Making";France;40-59;;;1/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Luxembourg;20-39;;;1/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;Malta;20-39;;;1/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Cyprus;above 60;;;1/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Slovenia;above 60;;;1/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Decision-Making";Iceland;40-59;;;1/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Spain;40-59;;;1/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Decision-Making";New Zealand;40-59;;;1/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;China;40-59;;;1/4/25
Fully agree;;Neutral;;Partly agree;;Fully agree;;Fully agree;;Partly agree;We already know that existing medical statistical models lead to bad outcomes for people of colour. So, if AI is based on these flawed models, we can expect inequities to be perpetuated.;Fully agree;;"Information Technology; Research; Management";USA;40-59;;;1/4/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Research; Management";Mexico;40-59;;;1/3/25
Fully agree;;Partly disagree;;Partly disagree;;Partly agree;;Partly disagree;;Fully agree;;Fully agree;;Research;USA;20-39;;;1/3/25
Partly agree;;Fully agree;;Partly agree;;Partly disagree;;Fully disagree;;Partly disagree;;Partly disagree;;"Artificial Intelligence; Public Authority";Deutschland ;above 60;It would be great to have a similar survey about the advantages of Medical AI.;peterwmendler@gmail.com;1/3/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Taiwan;20-39;;;1/3/25
Neutral;This argument does not deny that risks exist but asserts that the claim overemphasizes the negatives and underestimates the capacity of both AI technology and human oversight to prevent harm.;Neutral;we need strict regulation, otherwise scientists will do harm;Neutral;not sure about this either;Neutral;I do not understand this question ?;Fully agree;More information is not necessarily more knowledge. I agree;Neutral;I do not understand this question.;Neutral;However, the degree to which these challenges manifest depends on the design, implementation, and monitoring frameworks in place. Independent oversight can complement self-evaluation to ensure balanced and trustworthy decision-making processes.;;USA;40-59;The term sin is not good here, due to its deep cultural, religious, and emotional connotations that extend far beyond its literal meaning - the authors should not use such words in scientific context. Moreover, gender aspects and queer theories are not covered, so it is also underrepresenting human culture.;;1/3/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Management";Hong Kong;20-39;;;1/3/25
Fully disagree;;Partly disagree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Partly agree;;"Medicine; Artificial Intelligence; Research; Decision-Making";Italy ;20-39;;;1/2/25
Partly disagree;;Fully agree;;Fully disagree;;Partly agree;;Partely agree;;Partly agree;;Partly agree;;"Artificial Intelligence; Research";Italy;40-59;;tommaso.colafiglio@poliba.it;1/2/25
Partly agree;;Fully agree;;Neutral;;Partly disagree;;Fully agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Research";Italy;20-39;;;1/2/25
Fully agree;AI is not ready to work alone. However, we should see AI as a tool that support human decision making rather than a solution maker machine. ;Fully agree;Regulation should safeguard human integrity without preventing innovation and progress. ;Partly agree;I think that human patient-doctor interaction in medicine is important to build trusth in the process. AI should not replace the figure of the medic, but support it.;Neutral;;Fully agree;;Partly agree;;Partly agree;;"Artificial Intelligence; Research";Italy;20-39;;peppe.fasano99@gmail.com;1/2/25
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Artificial Intelligence;Italy;20-39;;angela.lombardi@poliba.it;1/2/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Management;Ethiopia;40-59;We do not have peopel here, so we need this AI urgently;;1/2/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Japan;40-59;;;1/2/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Management";Pakistan;20-39;;;1/2/25
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";Indonesia;40-59;;;1/2/25
Fully agree;Trust is key for a successful clinical implementation ;Partly agree;;Neutral;AI could be used for routine tasks, leaving health care professionals to improve patient -doctor relationship ;Fully agree;;Fully agree;It is important to involve clinicians in the development and deployment of AI tools ;Fully agree;Personalised solutions are important ;Fully agree;Multicentric and multi country datasets for validation is necessary.;Artificial Intelligence;Spain ;40-59;;oliver.diaz@ub.edu;12/31/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Turkey;40-59;;;12/31/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Management";Philippines;40-59;;;12/31/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Decision-Making";Bangladesh;above 60;;;12/31/24
Fully agree;"AI is quite a simplistic overrated process, which aims to imitate ""thinking"" of a brain. But it does not think or reason, but only works with the appearance of reason or thinking. Many aspects of real logic can be missed by AI. It delivers great results in very tightly scoped environments and situations, but is unfit to create real solutions in most real life situations.";Partly agree;"For research there should be no limits or regulations, except for ethical concerns. All technological aspects need to be examined, to better understand the internal workings of AI. This freedom from regulation is valid for research.
The application of AI, on the other hand, needs to be strictly regulated to ensure safety. ";Partly agree;Yes, this is true for those patients who expect human interaction with their doctor. Experiences with current automated phone interaction systems and AI chat bots show how limited such systems are. And a good doctor will have true compassion and empathy and not just imitate those as an AI system would do. However, other patients may just need sound health advice and diagnosis, and may not care for compassion. So it depends on the patients and their individual expectations.;Fully agree;"AI can be easily manipulated by those who program it or ""teach"" it. It can develop severe bias. Metrics in health care must ALWAYS have patient outcomes on top. But this manipulation of metrics is not only related to AI, but to other decisions in health care, where metrics other than patient care are often placed on higher priority.";Partely agree;"Depends on the patient: There is never ""too much"" information, in the same way as one never can be too rich or too healthy. It is good to get all and detailed information about all the background. However, there is of course the risk that all this information may be misinterpreted by patients who are not health experts. It helps then also to educate patients so that they understand the context of this detailed information.
False predictions are indeed very damaging and will not only decrease trust, but are actually harmful to the patient. I myself, however, would anyway never trust an AI system to give a proper advice and therefore my trust in it cannot be decreased because it is ZERO. But the trust can be in fact increased by correct predictions. ";Fully agree;Statistics is the basics, but then it needs to be applied to the specific patient circumstances.;Fully agree;"AI systems are in principle STUPID. The term ""intelligence"" in AI is actually a misnomer. AI itself is nothing more than a pattern matching algorithm that attempts to minimize its errors. It has NO internal reasoning whatsoever and solely tries to correlate input with output (based on what it has learned). Therefore, AI systems MUST be monitored by true human experts to ensure that their health advice is proper.";"Artificial Intelligence; Information Technology; Research";Germany;above 60;;;12/28/24
Partly agree;;Fully agree;;Partly disagree;;Partly agree;;Partely agree;;Partly agree;;Partly agree;;"Artificial Intelligence; Information Technology; Management; Public Authority";USA;40-59;;;12/28/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Decision-Making";Indonesia;40-59;;;12/27/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Nigeria;above 60;for Africa AI is a big chance as we have no peopel;;12/27/24
Fully agree;;Partly agree;;Fully agree;;Partly agree;;Partely agree;;Fully agree;;Partly agree;;"Artificial Intelligence; Research";UK;40-59;;;12/27/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Denmark;20-39;;;12/26/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Management";Latvia;40-59;Thanks for this important survey!;;12/26/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Sweden;20-39;;;12/26/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Poland;40-59;;;12/26/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Management";Paraguay;above 60;;;12/24/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Myanmar;above 60;hopefully AI wil also bring peace to us;;12/24/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";New Zealand;40-59;;;12/24/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";UK;40-59;;;12/24/24
Fully agree;;Partly disagree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;"Medicine; Research";USA;20-39;;ashley.woods76@gmail.com;12/24/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;Partly agree;;Artificial Intelligence;Germany;40-59;;;12/23/24
Partly agree;"It is not clear what ""adequate"" means. Some clinical stakeholders (radiologists, pathologists) could push ""adequate"" to extreme to avoid AI clinical use.";Fully agree;I guess this is related to sin 1.;Fully disagree;Patient satisfaction is overrated, in my opinion. I want to be cured, not satisfied.;Fully agree;This is vague or miss-worded. Not clear what AI metrics would not align with patient outcomes. Clinical AI systems should have metrics based on patient outcomes (this is how I would phrase it).;Fully agree;"Again, vague. Not sure what ""too much information"" is. In my opinion, for patients, the information (explanation) doesn't matter. As many time going to the doctor, the patient does want to know why he is sick, but only wants to get well. ";Fully agree;In my opinion, statistics in medicine is an excuse for lack of knowledge.;Partly agree;Again, transparency is only required by clinicians as an excuse for not using AI.;"Medicine; Artificial Intelligence; Research";USA;above 60;To explain my point of view: I am not a clinician and I also do military research where transparency is not required and the results are clearly related to outcomes (kill the target or not).;popescum@missouri.edu;12/23/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Iceland;40-59;;;12/23/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Management";Nigeria;above 60;We need AI to compensate our lack of human doctors;;12/23/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Austria;20-39;;tessa.pulli@gmail.com;12/22/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Hong Kong;40-59;;;12/22/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Decision-Making";Ethiopia;above 60;I think that this new AI will bring a lot of benefits to Africa - where we do not have many doctors!!;;12/22/24
Neutral;aber ich frage mich wer denn das verfizieren kann ...;Neutral;dennoch denke ich dass Forscher nicht alles dürfen sollen;Neutral;"bin nicht sicher, wenn ich an den übermüdeten grantigen Wiener Arzt denke - möglicherweise ist der Roboter da ""humaner"" ...";Neutral;die Frage verstehe ich nicht ganz - bin nicht aus diesem Feld;Fully agree;wenn ich richtig verstehe meint das dass zuviel Information zu Overload führt?;Neutral;theoretisch gut, aber wie soll das praktisch gehen - ich geh zum Arzt, der führt seine 08/15 rountine durch - mein Hintergrund ist ihm wurscht ... fährt mal alles ab, was Geld bringt ...;Neutral;die Frage die sich mir stellt: können wir da überhaupt einen Überblick behalten???;Information Technology;Austria;20-39;Danke dass ich darauf aufmerksam gemacht wurde, ich hoffe ich hab nicht zuviel Blödsinn reingeschrieben, aber ich denke dieses Survey ist wichtig - auch wenn ich nicht vom Fach bin;;12/22/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Decision-Making";Japan;40-59;Thank you very much for carriygn out this important survey!;;12/22/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Thailand;20-39;;;12/22/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Vietnam;40-59;;;12/22/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Management";Indonesia;above 60;;;12/22/24
Fully agree;Fully agree, but there is more to this. When using AI, we as humans do not go through thought processes required to perform this task on our own. If we are very familiar with this, the impact will be low to non-existent. But if these thought processes are rather new and not part of our daily routine, using AI may hinder us from learning them. Therefore, I would extend blind trust to unaware usage, even if there is some skepticism towards results generated by an AI.;Neutral;That‘s a hard one. Regulation can introduce better benchmarking, therefore enhancing the quality (while limiting the speed of innovation).;Partly disagree;A stethoscope didn‘t do that. I regard AI as a tool, it rather matters how it is used.;Fully agree;The question is: What does „overall“ mean? Where do you set the boundaries for the patient population regarded?;Fully agree;;Partly agree;What might be suboptimal for an individual might still be the optimal decision when globally regarding a population. The classical optimization dilemma.;Fully agree;Couldn‘t agree more. However, oversight can be implemented terribly too.;"Artificial Intelligence; Information Technology; Research";Germany;20-39;;tom.bisson@charite.de;12/21/24
Partly agree;;Partly agree;;Fully agree;;Partly agree;;Partely agree;;Fully agree;;Partly agree;;Management;Greece;40-59;;stella.lianou@gmail.com;12/20/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Decision-Making";Egypt;above 60;;;12/19/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Management";Marocco;;very important - thank you;;12/19/24
Fully agree;;Fully agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research; Decision-Making";Germany;20-39;;;12/19/24
Fully agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;;USA;;;;12/19/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Research; Decision-Making";China;40-59;;;12/19/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Management";Colombia;40-59;;;12/19/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Austria;40-59;"All questions are very general, more or less obvious, no really challenging / crucial topics are dealt with! Some questions seem very biased (eg. ""over-regulation"") and not formulated in a neutral way.
";;12/19/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Ecuador;40-59;;;12/18/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Mexico;40-59;;;12/18/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Decision-Making";Japan;above 60;AI is our big hope!;;12/18/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Management; Decision-Making";Korea South;above 60;;;12/18/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Research; Management";Vietnam;above 60;;;12/18/24
Fully agree;I have discussed this matter with medical experts, and it is clearly an issue. ;Neutral;In health-related issues (and in anything related public services directly affecting citizens) I do prefer due regulation to a profit-based American style deregulation.;Neutral;Yes and no, I do not see AI replacing the human at the point of care any time soon. Dehumanization comes from not enough human resources.;Partly agree;The data-centric nature of most AI could certainly bias the nature of medical decision making;Partly disagree;Do not see this being much of a central problem any time soon;Partly disagree;This is not a matter of AI, but a systemic issue, with advantages and disadvantages;Neutral;Again, this is a potential issue, but very marginal in the medical setting;Artificial Intelligence;Spain;40-59;;alfredo.vellido@upc.edu;12/18/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Research; Management";Australia;above 60;;;12/18/24
Fully agree;I agree that blind trust is not acceptable, but AI systems are getting better and better methods for testing them are being developed.;Partly disagree;I agree on the importance of regulations to prevent harm, protect privacy, etc but I believe a system has to be set up to examine each request, very much like the Institutional Review Board system in the US.;Partly agree;I agree when a doctor is available and the doctor knows how to talk with patients, but there are situations where doctors are hard to find or overworked and a system that can talk to people and explain things in detail can be useful.;Neutral;An example here would have been useful. Of course, if the metric is to save money we know that will not produce the bets decisions for the patient.;Partely agree;False predictions are problematic but generating too much information in my opinion is not.;Partly agree;Yes, statistics are applied to populations.  However, in some cases they are the best tool to use.;Fully agree;I agree.  I am not aware of systems that rely only in themselves.  Systems are trained on data, the training and validation processes are well known,;Artificial Intelligence;USA;above 60;;;12/18/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;Canada;40-59;;;12/17/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Partely agree;;Partly agree;;Partly agree;;"Artificial Intelligence; Information Technology; Research";USA;40-59;;;12/17/24
Fully agree;spurious correlations are a huge problem, particularly in high-stake applications such as medical AI;Partly agree;;Fully agree;;Partly agree;;Partely agree;;Partly agree;;Fully agree;;Artificial Intelligence;Germany;20-39;;frederikpahde@gmail.com;12/17/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Management";Serbia;above 60;;;12/17/24
Fully agree;No AI system with substantial impact should be used without appropriate validation.;Neutral;This is a difficult point for me. I believe regulation is necessary, but we should also be careful not too overregulate (especially to stay competitive to countries that do not). Finding a good balance is key (but the question is how?).;Partly agree;I believe AI systems in medicine should be complimentary to human doctors, and that a human iteraction is still necessary. However, complimentary systems can have a lot of values.;Fully agree;Systems optimizing for other metrics are by nature not optimizing the patient outcome.;Fully agree;;Fully agree;Looking at the appropriate context is necessary.;Fully agree;A human in the loop to verify the system is necessary.;"Artificial Intelligence; Research";Belgium;20-39;;sofie.goethals@uantwerpen.be;12/17/24
Fully agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;;USA;;;;12/17/24
Fully agree;;Partly agree;;Fully agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;Management;USA;40-59;;;12/17/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Management";Suriname;above 60;;;12/17/24
Partly agree;the problem i see is that this will be far too complex to validate or verfiy - it goes beyond human capacity;Neutral;I think we need legal regulations and prohibit research in these extreme areas - also research needs boundaries;Neutral;I do not know what could be done here;Neutral;do not understand the question;Neutral;we need the information - not just the results;Neutral;AI is statistics or?;Neutral;can this be done ? see question above - not sure;"Medicine; Information Technology; Decision-Making";Belgium;above 60;I have too less experience with what is called AI - but for my gut-feeling we need regulations;;12/17/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Decision-Making";Namibia;above 60;I see a big chance for us in Africa;;12/17/24
Fully agree;;Partly disagree;;Fully agree;;Partly disagree;;Fully agree;;Partly agree;;Partly disagree;;"Artificial Intelligence; Research; Decision-Making";Germany ;20-39;;;12/17/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Research";Bangladesh;above 60;I do not know what can be done with AI - but I feel that it is important;;12/17/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Decision-Making";Nigeria;above 60;for Africa AI is a big chance;;12/17/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Indonesia;40-59;very important survey;;12/17/24
Partly disagree;;Fully agree;;Partly disagree;AI systems, when trained well, could do better decisions than humans, since they can act fact-based and could have access to more information a human could possibly have in the back of his/her mind.;Partly disagree;;Partly disagree;Humans also do false predictions and it does not necessarily decreae trust.;Neutral;;Partly agree;;Medicine;Germany;20-39;;;12/17/24
Fully agree;;Partly disagree;;Partly disagree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Research";Italy;20-39;;elenasofia98@gmail.com;12/16/24
Fully agree;no AI - no harm to people - that easy - we must prohibit Ai systems;Fully disagree;we need full regulation to prevent research ;Fully agree;must be punihsed;Neutral;I do not know what this question means ???;Fully agree;;Neutral;is statistics not AI?;Neutral;who should oversee these sysytems - I do not know;"Medicine; Management";Luxembourg;above 60;;;12/16/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Paraguay;40-59;;;12/16/24
Fully agree;;Fully agree;no regulation should prevent research;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;Ai will be better than human doctors for sure;"Medicine; Research";Estland;40-59;;;12/16/24
Fully agree;;Fully agree;we need full regulation - no free research should be allowed !!!;Fully agree;Dehumanizaiton should be punished and legally sued!;Fully agree;;Fully agree;we need laws!;Fully agree;;Fully agree;not at all;"Medicine; Management; Decision-Making";Luxembourg;above 60;;;12/16/24
Fully agree;;Neutral;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;"Medicine; Research";Montenegro;above 60;;;12/16/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research; Management";Malta;40-59;;;12/16/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Iceland;40-59;;;12/16/24
Fully agree;It is true for any system, not particularly AI systems.;Fully agree;;Partly agree;Doctors often act according to standard manuals to avoid law suits, empathy is already lost. ;Fully agree;;Fully agree;;Fully agree;;Partly disagree;Self-supervision is quite mature and reliable. ;"Artificial Intelligence; Information Technology; Research; Management; Public Authority; Decision-Making";Pakistan;40-59;;;12/16/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;Artificial Intelligence;Portugal;40-59;;ana.f.sequeira@inesctec.pt;12/16/24
Partly agree;;Partly agree;;Neutral;;Partly agree;;Fully agree;;Neutral;;Partly agree;;;Austria;20-39;;;12/16/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Research";Mexico;above 60;;;12/16/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Research";Poland;above 60;;;12/16/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research; Management";Australia;above 60;;;12/16/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";France;above 60;;;12/16/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Pakistan;40-59;AI will solve many problems for sure;;12/15/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Research";Nigeria;40-59;the only chance we have here in Africa is help from AI;;12/14/24
Fully agree;;Neutral;I think we need also freedom for progress;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";China;40-59;;;12/14/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Research";Pakistan;40-59;;;12/14/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research; Decision-Making";Indonesia;40-59;this is a very important survey - thank you very much!;;12/14/24
Partly agree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Australia;20-39;;arman.safavi@student.unsw.edu.au;12/14/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Artificial Intelligence;Brazil;40-59;;;12/14/24
Fully agree;;Partly disagree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;"Information Technology; Research";Slovenia;20-39;;;12/13/24
Fully agree;;Fully agree;;Fully disagree;;Partly agree;;Fully agree;;Partly agree;;Partly disagree;;"Artificial Intelligence; Research";Australia;20-39;;;12/13/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Brazil;20-39;;;12/13/24
Fully agree;;Partly disagree;;Fully agree;;Fully agree;;Fully agree;;Partly disagree;;Partly agree;;Research;Australia;20-39;;henrybolt20@gmail.com;12/13/24
Fully agree;AI can make mistakes which should be verified.;Partly agree;Over regulation may inhibit progress, but regulation is still important.;Fully agree;Human interaction is very important to patients as it builds trust. ;Fully agree;AI can easily try to optimise to averages that are good for only part of the population but detrimental to individuals ;Partely agree;Over fitting is a huge problem for Aai and it can occur in health as well.;Fully agree;Every person is different and has different optimal health values.;Fully agree;There is too much AI content generated and AI cannot regulate itself as a mistake in one is very likely to be in all AI models.;;Australia;20-39;;;12/13/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Australia;20-39;;parvin.mansouri@gmail.com;12/13/24
Fully agree;"This is a bad question because it is circular. I.e why would validation be inadequate if not for the model producing incorrect decisions.

";Partly disagree;I disagree. The problem with excessive regulation is that only large companies and governments will retain access to powerful AI technologies, but they will still be able to innovate.;Partly disagree;"Wording is bad. ""Can"" just suggests that its possible. Sure, just about anything ""can"" happen. What matters is whether its likely.";Fully disagree;Any optimisation algorithm is going to prioritize metrics. It's literally how optimisation works.;Fully disagree;I disagree because the AI system probably isnt causing the confusion. Poor communication from the analyst is what causes confusion.;Fully disagree;If imporant individual patient circumstances arent being considered, then the model is bad. This is a matter of using a flawed model, not a statistical model.;Neutral;I think the bigger issue here is bias, not accountability. Presumably someone is still accountable (legally at least);"Medicine; Artificial Intelligence; Information Technology; Research";Audtralia;20-39;;eyvktzvl5@mozmail.com;12/13/24
Fully agree;;Fully disagree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Australia;20-39;;a.khazaal@unsw.edu.au;12/13/24
Partly agree;;Neutral;;Partly agree;;Neutral;;Partely agree;;Partly agree;;Neutral;;"Medicine; Artificial Intelligence; Research";Australia;20-39;;;12/13/24
Partly agree;;Fully agree;;Partly agree;;Partly agree;;Partely agree;;Partly disagree;;Partly agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Australia;20-39;;;12/13/24
Fully agree;;Fully agree;;Fully disagree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;;Singapore;20-39;;ericotjoa@gmail.com;12/12/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Management";Australia;above 60;;;12/12/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";New Zealand;40-59;;;12/12/24
Partly agree;;Fully agree;;Fully agree;;Neutral;;Partely agree;;Partly agree;;Partly agree;;Medicine;Czech Republic;20-39;;;12/11/24
Fully disagree;;Neutral;;Fully disagree;;Fully disagree;;Neutral;;Fully disagree;;Fully disagree;;Medicine;Austria ;20-39;;;12/11/24
Fully agree;;Neutral;;Fully agree;;Partly agree;;Partely agree;;Neutral;;Partly agree;;Medicine;USA;20-39;;;12/11/24
Fully agree;;Partly agree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Partly agree;;Research;Austria;40-59;;;12/11/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Indonesia;40-59;;;12/11/24
Fully agree;;Partly agree;;Fully agree;;Neutral;;Fully agree;;Partly agree;;Partly disagree;;"Artificial Intelligence; Research";USA;20-39;;;12/11/24
Neutral;;Partly agree;;Partly agree;;Neutral;;Fully agree;;Partly agree;;Partly agree;;Artificial Intelligence;USA;20-39;;;12/11/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Australia (Sydney Area);40-59;;;12/10/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Thailand;40-59;;;12/10/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";South Korea;40-59;;;12/10/24
Fully agree;;Partly agree;;Partly agree;;Partly disagree;;Fully agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Information Technology";India ;20-39;;dheeraj.singh@paruluniversity.ac.in;12/10/24
Partly disagree;;Fully agree;;Partly disagree;;Partly disagree;;Fully disagree;;Partly disagree;;Partly disagree;;"Artificial Intelligence; Information Technology; Research";India;40-59;;mayuri.mehta@scet.ac.in;12/10/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;We also need to rely on rule systems to integrate knowledge graph to prevent such situation;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";China;40-59;This is a great work;hongsun502@gmail.com;12/10/24
Fully agree;;Partly agree;;Neutral;;Partly disagree;;Neutral;;Partly agree;;Neutral;;"Information Technology; Research; Management";Switzerland;40-59;;angelo.consoli@supsi.ch;12/10/24
Fully agree;;Partly agree;;Partly disagree;;Partly agree;;Partely agree;;Partly agree;;Neutral;;Research;South Korea;40-59;;secutron@naver.com;12/10/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Management; Public Authority; Decision-Making";Greece;above 60;;;12/10/24
Fully agree;;Partly agree;"That's what ""excessive"" means. Regulation is necessary, however";Partly agree;Read studies that AI systems might be actually better at empathizing, which improves patient satisfaction;Partly agree;;Partely agree;;Fully agree;;Partly agree;;"Artificial Intelligence; Information Technology; Research; Decision-Making";Japan;20-39;;;12/10/24
Fully agree;;Partly disagree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Australia;40-59;;;12/9/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Management";Estland;40-59;;;12/9/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Public Authority; Decision-Making";Belgium;above 60;;;12/9/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Management; Decision-Making";Egypt;above 60;;;12/9/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Switzerland;above 60;;;12/9/24
Fully agree;;Partly agree;;Partly disagree;;Fully agree;;Fully agree;;Fully agree;;Neutral;;Artificial Intelligence;Germany;40-59;;kersting@cs.tu-darmstadt.de;12/8/24
Partly agree;;Partly agree;;Neutral;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;;India;40-59;;r.einoeder@hotmail.com;12/8/24
Fully agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;We absolutely should not allow self working!;Information Technology;Slovenia;above 60;;matjaz.debevc@guest.um.si;12/7/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Research; Decision-Making";Italy;above 60;;;12/7/24
Partly agree;;Neutral;;Partly disagree;;Neutral;;Partly disagree;;Partly agree;;Partly agree;;;USA;20-39;;;12/7/24
Fully agree;;Partly disagree;;Partly agree;;Fully agree;;Fully agree;;Fully disagree;;Partly agree;;;Slovakia ;20-39;;;12/7/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology";Switzerland;above 60;;;12/7/24
Fully agree;;Fully agree;;Neutral;depend on the case. for generic medicine i will prefer a fast AI answer. ;Partly agree;;Fully agree;;Fully agree;that is te reason why we need context aware AI;Partly agree;;Artificial Intelligence;Canada;40-59;;elsaddik@uottawa.ca;12/7/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Management; Public Authority";Deutschland;above 60;;;12/6/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";South France;above 60;;;12/6/24
Fully agree;;Fully agree;;Fully agree;;Partly agree;;Partely agree;;Fully agree;;Fully agree;;Medicine;Australia;20-39;;;12/6/24
Fully agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;That happened to me, when i asked ChatGPT what the pathogenesis of a certain disease was. It tried to predict what the pathogenesis was based on its general knowledge, but since it did not have info about that certain disease, it made a terrible and fully wrong explanation of the disease. And since it was based on other general medical knowledge, to an unsuspect person it could look like a true info ...;Fully agree;;Fully agree;;Medicine;Slovakia;20-39;;viktorbaan.de@gmail.com;12/6/24
Neutral;;Partly agree;;Partly agree;;Neutral;;Partely agree;;Partly agree;;Neutral;;Decision-Making;Slovakia;20-39;;maria.chudjakova@gmail.com;12/6/24
Fully agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;Slovakia;40-59;;;12/6/24
Partly agree;I would say that it depends on the quality of the specific AI tool.;Partly agree;;Partly agree;;Fully agree;;Fully agree;Again, I would say that it depends on the quality of the specific AI tool.;Fully agree;;Fully agree;;Research;Slovakia;40-59;;;12/5/24
Fully agree;;Partly agree;The fear of under regulation is valid but we should set a balance of regulation and an encouraging environment for innovation.;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Philippines;20-39;;ndgonda@up.edu.ph;12/5/24
Partly agree;;Partly disagree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Research";Philippines;20-39;;;12/5/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology";Hungary;above 60;;;12/5/24
Fully agree;;Fully agree;;Neutral;;Partly agree;;Partely agree;;Neutral;;Partly agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Slovakia;20-39;;;12/4/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Management";Malta;above 60;;;12/4/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Italy;above 60;;;12/4/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Decision-Making";Slovenia;above 60;;;12/4/24
Fully agree;Ich persönlich bin nicht sonderlich von der Idee der künstlichen Intelligenz überzeugt. ;Partly disagree;Grundsätzlich sind natürlich Regulierungen, wie der Name erahnen lässt, eine Einschränkung. Da ich allerdings der Überzeugung bin, dass KI nur in Bereichen, in denen der Mensch absolut noch nicht ausreichend ist, wie Medizin und dergleichen, tatsächlich wichtig und richtig ist. Bin ich auch davon überzeugt, dass man die Einschränkungen durchaus benötigt, um KI nicht in Bereichen einzusetzen in welchen sie nur die menschliche Faulheit unterstützt. ;Fully agree;Roboter und KI-Systeme sind in der Medizin durchaus wichtig, sofern es sich beispielsweise um Operationen oder Ähnliches handelt. Die menschliche Interaktion darf auf gar keinen Fall verloren gehen. Noch darf die Technik die menschliche Arbeitskraft in der Medizin völlig überflüssig machen. Wir brauchen immer noch Ärzte und Krankenschwestern und alles darum herum.  ;Fully agree;;Fully agree;Auch ein KI-System ist nur eine Ausgeburt des menschlichen Verstandes und deshalb ebenso fehleranfällig. ;Fully agree;Die persönliche Komponente kann ein Computer natürlich nicht so gut miteinbeziehen wie ein Mensch. ;Fully agree;Ich würde mich niemals einzig und alleine auf einen Computer verlassen. ;;Österreich;20-39;"KI ist gut, solange sie in gewissen Maßen und nur in bestimmten Bereichen eingesetzt wird!!!!
";;12/4/24
Fully agree;;Neutral;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;Medicine;Slovakia;20-39;;;12/4/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;Medicine;Australia;20-39;;;12/4/24
Fully agree;;Fully agree;;Partly agree;;Partly disagree;;Partly disagree;;Partly agree;;Partly agree;;;USA;20-39;;;12/4/24
Fully agree;;Neutral;;Partly agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;;Austria;20-39;;fabian.omasics@boku.ac.at;12/4/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Research";Bosnia;above 60;;;12/4/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Croatia;above 60;;;12/4/24
Fully agree;;Fully agree;;Fully agree;;Fully disagree;AI is not responsible for bad training. The trainer is.;Fully disagree;;Fully agree;Agree, but the same is valid for human doctors.;Neutral;;Information Technology;Slovakia;40-59;;radoslav.vargic@stuba.sk;12/4/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;"Artificial Intelligence; Information Technology";Slovakia;20-39;;jozef.goga@stuba.sk;12/4/24
Fully agree;;Fully agree;;Partly disagree;"Already ELIZA has showed in the 1960s that humans may feel understood with compassion and empathy also  by a communication with machines. I would prefer an AI system that „simulates“ compassion and that has enough time to interact with me in detail, rather than have only 3 to 5 minutes of a stressed human doctor.
I would say it is a question of the quality of an interactive AI system.";Partly disagree;The question is a bit too simplistic. The AI system has to be trained precisely to the specific application, in order to be used e.g. as diagnostic tool. Where the system is intended to assist in therapy decision, it is of course indispensable, to target the overall patient outcome and not just some solitaire indicators.;Fully agree;;Fully agree;"Again, this is a bit simplistic, but at the core, this is right. A correct a precise definition of the application domain (distribution of patiient ciriteria)  and target (together with statistical performance) is the basis for digital evidence-based medizin. 
It is the duty of the administering human doctor, to judge, if the patient circumstances are within the limits of the application domain. Only then are the resulting decisions valid, in the sense that they are statistically optimal.";Partly agree;"The question is not totally clear. A system that creates predictions should be monitored on the basis of the ground truth of the actual outcome. As far as the monitoring of the running system is concerned, if objective outcome data is avalable, then of course the comparison with that ground truth is crucial. 
";"Artificial Intelligence; Information Technology";Austria;40-59;"Correct certification (testing) of the AI system 
(1.)derive Minimum performance requirements from risk analysis, 
(2.) sample independent test-set, 
(3.)) empirical test of MPR on test set  
Are the evidence-based essential statistical guarantee for a trustworthy AI system in medical applications. (See TRUSTIFAI, Software Competence Center Hagenberg, …)";bernhard.nessler@scch.at;12/3/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;;USA;;;;12/3/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Hungary;above 60;;;12/3/24
Fully disagree;there are studies showing that diagnosis of AI systems are better than diagnosis of  physicians and also better than  physicians supported by AI systems, because physicians do not trust AI systems;Fully agree;;Partly disagree;better diagnosis will party compensate the loss of empathy,  ;Neutral;;Fully agree;;Partly agree;;Partly agree;;Management;Austria;above 60;;bee1hoven@gmail.com;12/3/24
Fully agree;;Partly agree;;Partly disagree;;Partly agree;;Fully agree;;Partly agree;;Partly agree;;"Management; Decision-Making";Austria;above 60;;josef.schrrey@aon.at;12/3/24
Fully agree;They are prone to overfitting training data and other technical issues.;Fully agree;;Partly disagree;;Neutral;;Partely agree;;Partly agree;;Partly agree;;"Artificial Intelligence; Information Technology; Research";Canada;20-39;;simaa.ataei@gmail.com;12/2/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Management; Public Authority";Slovakia;above 60;;;12/2/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Management";Slovenia;above 60;;;12/2/24
Fully agree;;Partly disagree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";USA;40-59;;cjsmith@sei.cmu.edu;12/2/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Brazil;above 60;;;12/2/24
Fully agree;;Partly agree;;Partly disagree;;Neutral;;Partely agree;;Fully agree;;Partly disagree;;Information Technology;Austria;20-39;;;12/2/24
Fully agree;;Partly agree;;Fully agree;;Partly agree;;Partely agree;;Fully agree;;Partly agree;;;Austria;20-39;;;12/2/24
Partly agree;;Neutral;;Partly disagree;;Partly disagree;;Partely agree;;Partly agree;;Partly agree;;"Medicine; Artificial Intelligence; Research";FINLAND;20-39;;;12/2/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Brazil;20-39;;;12/2/24
Partly agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;Partly agree;;Partly agree;;Research;USA;20-39;;;12/2/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Partely agree;;Fully agree;;Fully agree;;;Austria;20-39;;;12/2/24
Fully agree;;Partly disagree;;Fully agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;;Austria;20-39;;;12/2/24
Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Austria ;20-39;;;12/2/24
Partly agree;;Neutral;;Partly agree;;Partly agree;;Fully agree;;Partly agree;;Partly agree;;Medicine;USA;above 60;The word Sin is highly loaden, and not appropriate for an international survey as it is biased, we should always stay inclusive and gender neutral;;12/2/24
Partly agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;;Austria;below 20;;;12/2/24
Partly agree;;Fully agree;;Partly agree;;Partly agree;;Partely agree;;Partly agree;;Neutral;;;USA;20-39;;;12/2/24
Fully agree;please check in your research work how to disentangle between decision making and causing harm;Fully agree;Strict regulations like e.g. in the European Union block research and make innovation extremely difficult with the effect that then the researchers go outside Europe!;Partly disagree;It is assumed that an AI has definitely more time and empathy than an agressive, overstressed and burnt-out human doctor - what would you prefere?;Neutral;this is a difficult question which needs a contextual background to be clearly answered - as I am not that kind of expert I rather prefer to stay neutral here;Neutral;I am also not sure about this - I am a medical doctor and we make much more errors than the patient would think - I would rather tend to see it as a chance to improve it - but rather stay neutral on that, not to destroy your statistics;Neutral;also the same here;Partly agree;What we would need here is a ground truth - but what is this truth ???;Medicine;Switzerland;above 60;Very good survey, and very important - however, I have too less experience with AI;;12/2/24
Fully agree;;Partly agree;;Partly agree;;Neutral;;Partely agree;;Partly agree;;Partly agree;;;USA;20-39;;;12/2/24
Fully agree;;Partly disagree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Research;Austria;20-39;;;12/2/24
Fully agree;;Fully disagree;;Partly agree;;Partly agree;;Partely agree;;Partly disagree;;Fully agree;;"Public Authority; Decision-Making";Austria;20-39;;;12/1/24
Fully agree;;Partly disagree;;Partly agree;;Partly agree;;Partely agree;;Partly agree;;Partly agree;;Research;Austria;20-39;;;12/1/24
Fully agree;;Fully agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";UK;40-59;;;12/1/24
Fully agree;;Partly disagree;;Fully agree;;Partly agree;;Fully agree;;Partly agree;;Partly agree;;;USA;20-39;;;12/1/24
Partly disagree;there is a lot room for ;Fully disagree;There is lot of potential in this subject and i think that it is a net positiv if there is a lot more research in the subject of ai;Partly agree;If the Ai is doing part of the assesment but there a still doctors around it can help the process;Neutral;;Partly disagree;yes but  i think that we still dont know the full potential of the Ai systems and in time it can help to get to better outcomes;Neutral;;Partly agree;;"Artificial Intelligence; Information Technology; Research";Austria;20-39;;;12/1/24
Fully agree;;Fully agree;;Neutral;;Neutral;;Partely agree;;Neutral;;Fully agree;;Information Technology;Austria;20-39;;;12/1/24
Fully agree;;Partly agree;;Partly disagree;;Partly agree;;Fully agree;;Fully agree;;Neutral;;;USA;20-39;;;12/1/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Artificial Intelligence;Denmark;20-39;;;12/1/24
Fully agree;;Partly disagree;;Fully agree;;Neutral;;Partely agree;;Partly agree;;Neutral;;;USA;20-39;;;12/1/24
Partly agree;As long as long proper human controllers are in the loop, effect of that harm could be minimal. ;Fully agree;Education is the key, but often researchers may not know who to seek answers and reassurance from! At some point you get exhausted about all the red lights and “you cannot share that” and even think about relocating to a location with fewer restrictions. ;Partly disagree;Current LLMs are sufficiently empathetic, but I do not believe that any AI system will ‘replace’ doctors in the near future. Rather they will be used as recommendation systems. ;Fully agree;Yes, and it takes a lot of conversations between the clinical and research teams to understand and quantify those metrics;Partely agree;Yes, such as the chatGPT and Gemini with their fake reference lists. ;Partly disagree;If those statistical models are representative of enough patient samples and rare cases, then those errors could be alleviated ;Fully agree;;"Artificial Intelligence; Research";Finland ;40-59;;mastaneht.83@gmail.com;12/1/24
Partly agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;;India;20-39;;;12/1/24
Partly agree;I recently had a surgery and asked AI if i could use nicotine. It disagreed but after asking if using it only today it said it would cause no harm. It did not educate me enough, because i started using nicotine regularely again after that day. ;Partly agree;;Partly disagree;;Neutral;i dont understand what that means.;Fully disagree;;Fully agree;;Fully agree;;;India;20-39;;;12/1/24
Fully agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;"Management; Decision-Making";Austria;20-39;;;12/1/24
Partly agree;;Fully agree;;Partly agree;;Neutral;;Partely agree;;Fully agree;;Partly agree;;"Medicine; Research";Austria;20-39;;;12/1/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Switzerland;above 60;;;12/1/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";UK;above 60;;;12/1/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Management";Germany;above 60;;;12/1/24
Fully disagree;;Partly agree;;Partly disagree;;Partly agree;;Partely agree;;Fully agree;;Partly agree;;Research;Finland;20-39;;;12/1/24
Fully agree;In medicine, this is a known problem - even without AI - sometimes called confirmation bias. AI has the potential to make this much worse.;Fully disagree;"Phamaceutical companies are heavily regulated, and somehow manage to produce new drugs and to remain highly profitable. In their case, regulation ""levels the playing field,"" prevent (some) abuses by big companies.";Fully agree;Just look at how medical insurance is now administered, through robotic recommendations. Human representatives can only try to explain the decisions, but cannot change those decisions. AI is already causing some of these abuses. Greater use of AI will lead to greater abuses. ;Partly agree;Holistic medicine - which can include measures of patient well-being, for example - is in retreat in many places, forced out by a focus on narrow metrics. This can be reversed, by including a broader array of metrics, and by including patients as co-evaluators of outcomes. The models can be re-computed and re-purposed toward more humane and human outcomes.;Neutral;"There is a problem with this item. Generating too much information is one kind of problem. Providing false predictions is a different kind of problem. Because this item combines two very different problems (different causes, different harms), the only answer I can give is ""Neutral.""";Partly agree;As with Sin 4, this is a real problem now. As with Sin 4, the statistical models can be modified to include individual patient circumstances. But who has the power to do this?;Fully agree;This is a known problem with ML validation. It is not restricted to medicine. It's also already known to be very bad practice. In this case, we could use current discourse in ML (e.g., in NeurIPS, etc.) to critique and correct this problem. The needed thought, principles, and practices are already available.;"Artificial Intelligence; Research";USA;above 60;"The rhetorical use of the word ""sin"" is prejudicial. I completed the survey anyway. However, I urge you to use more neutral language next time.

Also, each question should be accompanied by a ""decline to answer"" option. Or - if all questions are optional - that should be stated. The use of a red asterisk preceding each question makes it look like an answer is required.";;12/1/24
Fully agree;;Fully agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Artificial Intelligence;India;20-39;;;12/1/24
Fully agree;;Fully agree;;Neutral;I can think of several scenarios in which AI could enhance patient satisfaction and several scenarios where it could indeed lead to loss of empathy and decrease patient satisfaction.  ;Fully agree;;Fully agree;;Neutral;Depends on what is meant by statistical models - AI is in very large part about statistical models and so is current personalized medicine - albeit these are not stats models in the traditional sense.  Decision making should be informed and what other means we have for informed decision making than to base it on previous data. That's statistical models in wide sense.   ;Fully agree;;"Artificial Intelligence; Information Technology; Research";Finland;40-59;;;12/1/24
Neutral;but who is able to provide adequate validation/verification ???;Neutral;it must be a balance ;Neutral;not sure - if I think on bad mooded clinicians who have not slept for the last 30 hours ... then maybe a chat-bot has more empathy?;Neutral;I do not really understand what is here meant;Neutral;Assuming that information overload might be the problem?;Neutral;of course statistics is not always true, but if you constantly update your systems it might?;Neutral;again here - my question would be: who is today able to provide such an oversight ???;"Medicine; Information Technology; Management; Public Authority";Belgium;above 60;Very good survey - I hope I was not too critical;;12/1/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;this is very oversimplified - so that there is practically no change to click other than fully agree - who would not fully agree with these questions? I am assuming this is intended by this survey - kind of a justification of the statements - it this way this is very well done!;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Deutschland;above 60;;;12/1/24
Fully agree;Over-reliance on AI is particularly worrisome due to its shirt-terms as well as long term-effects, eg. Progressive deskilling and deresponsabilisation. ;Partly disagree;"Research should be as free and supported as possible, only considering some basic ethical principles. However medical technologies should undergo rigorous evaluation (see the concept of ""Technovigilance"")";Neutral;I still do not have too strong an opinion on this, since over-burdened doctors could sometimes display a less-than-robotic level of empathy.;Fully agree;"The targets of ootimizations are a crucial element to ensure the ethics of the system. A system whose target is heightened efficiency may be suboptimal for patient experience as a whole. Moreover it should bea ensired that the ""healthy patient"" target is representative of different ages, ethnicities and genders (vs. Adult cis white male)";Partely agree;"I am interested in ""Cognitive Overload"" and believe it is a clear problem. However, providing too much information could just as well needlessly increase unwarranted trust in a system, eg. In the case of a Decision Support Systems, a lot of information provided can be seen as supporting the proposed disagnosis - ""look how much information correlated to this diagnosis, I cannot even go through all of it, so it must be right""...";Fully agree;Especially for Diversity and Inclusion scenarios (different genders, ethnicities, ages, incomes...);Fully agree;;Artificial Intelligence;Italy;20-39;;chiara.natali@unimib.it;12/1/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management; Public Authority; Decision-Making";Germany;above 60;;;12/1/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Partely agree;;Neutral;;Neutral;;Medicine;USA;above 60;;;12/1/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";India;40-59;;;12/1/24
Fully agree;Sure. Who would be silly enough to trust random unchecked results?;Fully agree;Especially regulations (like the AI Act) that create so much legal uncertainty and ambiguity due to a lack of consistency with technical facts are harmful for the innovation.;Partly disagree;"I would regularly prefer high quality interactive AI systems that can also show empathy (which is perfectly possible and was already proven in the 1960s) instead of human doctors that have just 3 to 5 minutes time to talk per patient.
We should see such AI system at least as a valuable extension of treatments by human doctors.
";Fully disagree;The AI systems metric has to be aligned with the specific expected outcome in the specific place it is intended to be applied, be it a classification diagnosis, or a therapeutic decision. ;Fully disagree;The statement is too much simplified. A certain ratio of wrong predictions will necessarily occur (as this also happens by human doctors). Trust building necessitates clear communication about the risks.;Fully disagree;"This statement is too simplified. It is impossible to consider all patient circumstances, even human doctors can‘t guarantee that.
Obviously it leads to an increased rate of incorrect predictions if greater parts of the relevant inputs are not available.";Partly agree;It is fully possible (and in fact the goal of a well designed Ai system) to integrate independent oversight into the processes, life cycle and the monitoring of an AI system. However, it is true that without „grounding“, the performance can neither be tested nor improved.;"Artificial Intelligence; Information Technology; Research";Austria;40-59;"Actually I am scientific researcher in Machine Learning, specifically in the field of certification of AI systems.

bernhard.nessler@scch.at";bernhard.nessler@scch.at;12/1/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Holland;above 60;;;11/30/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology";England;above 60;;;11/30/24
Fully agree;;Fully agree;;Neutral;I am not sure what to say here - I think there are potential benefits of AI as well?;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";Germany;20-39;;;11/30/24
Fully agree;;Partly agree;"The term ""excessive"" is subjective. The purpose of regulation is to allow ethical development of technologies.";Fully disagree;We seem yet to be far from having human interaction fully replaced by AI systems. And even in the perspective of that possibility, if human interaction will be desired, it will be possible.;Partly agree;Sometimes patient outcomes must take into account their emotions, ethics, religious beliefs and life beliefs. ;Partely agree;AI is a fancy name for complex computer algorythms. If they provide false predictions, it's not the AI fault, they just need to be further developed. ;Fully agree;We all fall within some statistics. There's more variability than we think of.;Neutral;I wouldn't know;Medicine;Romania;20-39;;drgrigorieoana@gmail.com;11/30/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";Germany;20-39;;;11/30/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";France;above 60;;;11/30/24
Fully agree;kein Kommentar ;Fully agree;kein Kommentar ;Fully agree;kein Kommentar ;Neutral;Das gilt auch für Menschen.;Partely agree;kein Kommentar ;Fully agree;Da jeder Mensch ein Individuum ist, lässt er sich nur bedingt an Statistiken messen.;Fully agree;kein Kommentar ;;Germany;above 60;;;11/29/24
Fully agree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Partly agree;;Partly agree;;Research;Canada;40-59;;;11/29/24
Fully disagree;;Fully disagree;;Neutral;;Neutral;;Neutral;;Fully disagree;;Fully disagree;;Research;Canada;40-59;;;11/29/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Austria;below 20;I am not an expert in any of these areas, but I regard these seven sins as extremely important and this will become important in the future!!;;11/29/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Germany;above 60;;;11/29/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Research; Management; Public Authority";Belgium;above 60;;;11/29/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Greece;40-59;;;11/29/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Bulgaria;40-59;;;11/29/24
Fully agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Romania;20-39;;tudor.mehedinteanu@gmail.com;11/29/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Partely agree;;Partly agree;;Partly agree;;Medicine;Romania;20-39;;rodica.nagy25@gmail.com;11/29/24
Fully agree;;Partly agree;;Partly disagree;;Fully disagree;;Fully agree;;Partly disagree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";India;20-39;;;11/29/24
Fully agree;;Partly disagree;;Partly agree;;Neutral;;Neutral;;Partly agree;;Fully agree;;"Management; Decision-Making";Austria;20-39;;;11/29/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";Finland;40-59;;;11/29/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Public Authority";Belgium;40-59;;;11/29/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Partly disagree;;Partly agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Germany;40-59;;frank.fbi@gmail.com;11/28/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";UK;above 60;;;11/28/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Decision-Making";Ireland;40-59;;;11/28/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research; Management";Tunisia;40-59;;;11/28/24
Fully agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Romania;40-59;;;11/28/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Bulgaria;40-59;;;11/28/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";UK;40-59;;;11/28/24
Fully agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Decision-Making";Norway;40-59;;;11/28/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Belgium;40-59;very important survey;;11/28/24
Fully agree;;Partly disagree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Artificial Intelligence;Germany;20-39;;katharina.weitz@hhi.fraunhofer.de;11/28/24
Fully agree;Optimising expected losses does not prevent mistakes in a deterministic sense.;Fully agree;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Partly agree;;"Artificial Intelligence; Research";Singapore;40-59;Putting age groups finer would have been maybe more informative for you;alex.binder1979@gmail.com;11/28/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Management";Portugal;40-59;;;11/27/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";France;40-59;;;11/27/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research; Management";UK;40-59;;;11/27/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";The Netherlands;40-59;;;11/27/24
Fully agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research; Management";Germany;40-59;;;11/27/24
Partly agree;;Neutral;;Partly disagree;;Neutral;;Partly disagree;;Partly agree;;Fully agree;;"Medicine; Information Technology; Management";India;40-59;;;11/27/24
Partly agree;;Fully agree;;Fully disagree;;Fully agree;;Fully disagree;"the more information the better; no system is 100% perfect (also not humans) there will always be false predictions";Partly agree;;Partly agree;;"Artificial Intelligence; Research";Austria;20-39;;;11/27/24
Fully agree;;Partly agree;;Partly disagree;;Partly agree;;Fully agree;;Neutral;;Partly agree;;"Artificial Intelligence; Information Technology; Research";India;20-39;;;11/27/24
Fully agree;;Partly agree;;Partly agree;;Neutral;;Fully agree;;Partly disagree;;Fully agree;;Artificial Intelligence;India;40-59;;;11/27/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research; Management";Belgium;40-59;;;11/27/24
Fully agree;;Fully disagree;;Partly disagree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Management;Kärnten;20-39;;;11/26/24
Fully agree;;Partly disagree;;Partly agree;;Fully agree;;Partely agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";India;20-39;;;11/25/24
Fully agree;;Neutral;What means exzessive?;Partly agree;;Partly agree;;Partely agree;;Partly disagree;;Fully agree;;Decision-Making;Carinthia;40-59;;;11/25/24
Fully disagree;;Fully agree;;Partly agree;;Partly agree;;Partely agree;;Fully agree;;Fully agree;;Information Technology;Austria;40-59;;;11/25/24
Fully agree;At the end of a decision there must always be a human being. The military sector is worrying here.;Partly agree;In the catholic church in Austria we discuss the topic from an ethical and also from an technical perspective.;Partly agree;For example, in the image recognition of cancer, AI can produce very good results since many years.;Neutral;;Partely agree;;Partly agree;;Fully agree;;"Information Technology; Management";Austria - Klagenfurt;40-59;All the best with the evaluation;wolfgang@almer-online.com;11/25/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Romania;40-59;;;11/23/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;Vienna, Austria;20-39;;;11/22/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Finland;40-59;;;11/22/24
Fully agree;AI Systems are not infallible: AI systems are trained on data, and if that data is biased, incomplete, or inaccurate, the AI's decisions will reflect those biases - no blind trust !!!;Fully agree;Strict regulations can create a culture of fear, where researchers and developers are afraid to take risks and experiment with new ideas for fear of legal repercussions. Science needs freedom!;Neutral;"it's important to note that AI has the potential to augment and enhance the patient-doctor relationship, not replace it; however, I think that the effectiveness of an AI doctor would depend on its ability to provide accurate diagnoses and effective treatment plans, regardless of its personality. ";Fully agree;Carefully select metrics that directly correlate with improved patient health and quality of life.;Fully agree;Information Overload !!!;Fully agree;While statistics can provide valuable insights into population trends and probabilities, it's crucial to recognize their limitations when applied to individual cases. A common misconception is that statistical trends directly apply to specific individuals.;Fully agree;It's important to note that human oversight is not about micromanaging AI systems. Instead, it's about providing guidance, setting boundaries, and ensuring that AI systems are used responsibly. By working together, humans and AI can create a better future.;"Medicine; Artificial Intelligence; Research";Germany;40-59;Thanks to Professor Holzinger for making me personally aware of this important survey, I would otherwise nto have participated due to lack of time!!!;;11/22/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Decision-Making";Spain;40-59;;;11/22/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Luxembourg;40-59;;;11/22/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";UK;40-59;;;11/21/24
Fully agree;;Neutral;Í think it must be a good balance;Partly agree;it depends;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Norway;40-59;;;11/21/24
Fully agree;validation and verification are essential;Partly agree; ethical, social and safety aspects have to be considered and regulated strictly;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;This might end up in loops that are generating either one or the other outcome depending on the information used. Validation and verification gets difficult then.  ;Research;Austria;40-59;;;11/21/24
Fully agree;;Partly agree;;Neutral;"Chatgpt is often more friendly than humans, humans are often stressed
";Fully agree;;Partely agree;;Fully agree;;Partly disagree;;Research;Austria;20-39;;;11/21/24
Partly agree;Final decision making is not supposed to be done by AI alone if there is a potential risk for humans. ;Partly agree;;Partly disagree;There are probably many tasks which do not require human interaction. This could make resources free for tasks which require human interactions. ;Partly agree;;Partly disagree;"It's a developing tool and can have technical issues like any other technical device, machine or software
";Partly agree;;Fully agree;;Research;Australia;20-39;;;11/21/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;India;20-39;;;11/21/24
Fully agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;Research;Austria;20-39;;;11/21/24
Fully agree;;Partly agree;regulation is necessary however overregulation can inhibit usability ;Fully agree;especially in medicine, emphathy is of high importance - this AI cannot provide;Fully agree;medical treatments should always be tailored to the individual, taking into account the individual medical history, overall health and other potential health condiditions;Fully agree;;Fully agree;;Fully agree;"always ""human in the loop""";Research;Austria;20-39;;;11/21/24
Fully agree;;Fully disagree;;Partly disagree;i read about studies showing that people are happy with AI systems. Doctors are not always empathic either;Partly agree;;Fully agree;;Partly agree;;Fully agree;;Research;India;20-39;;;11/21/24
Fully agree;;Neutral;;Fully agree;patients need more care other than medicines;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Austria;20-39;;;11/21/24
Fully agree;;Neutral;I think regulation is important to bring research in the right track. So I am pro regulation. But yes it might also limit experiments;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;India;20-39;;squirrelz@gmx.de;11/21/24
Fully agree;validation and verfication is absolutely necessary !!!;Fully agree;yes of course;Neutral;I am not so sure !! Dcotors can also be grumpy !!!;Fully agree;yes;Fully agree;Iam fully convinced that this is the case!!!;Partly agree;I would partly agree ;Fully agree;yes, but who will really have the capacity of making such an oversight - humans? Another AI ???;"Artificial Intelligence; Information Technology; Research";Austria;40-59;this is an important survey ;;11/21/24
Fully agree;Shure, but in my opinion the question is already written in a very opinionating manner;Partly agree;;Neutral;Dependa in where IT IS done;Partly agree;;Neutral;;Fully agree;;Fully agree;;Research;South Africa;20-39;;;11/21/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Fully agree;;Partly disagree;;Neutral;;"Artificial Intelligence; Research";Austria;20-39;;;11/21/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;Research;India;20-39;;;11/21/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Portugal;40-59;;;11/21/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research; Management; Decision-Making";Spain;40-59;I have to fully agree with all questions - so it was really quick - thank you very much! I hate overly long questionaires - but this one is excellent!;;11/20/24
Fully agree;;Fully agree;I am seeing this problem now with regard to governance procedures being promulgated about the use of LLMs in medicine. No one seems to be able to figure out a way to titrate these to how these models will actually be used. For example, I have a VERY difficult time getting the governance committee to understand that my programmers use it just for writing code, with absolutely no patient information included.;Fully agree;;Fully agree;;Fully agree;I agree- I see this with LLMs, in fact!;Fully agree;Way too much unmeasured confounding, and most people (including docs) don't understand this, especially when it comes to chronic disease management.;Fully agree;;"Medicine; Artificial Intelligence; Research";USA;above 60;;jhholmes@pennmedicine.upenn.edu;11/20/24
Fully agree;;Neutral;we need a careful trade-off;Partly agree;maybe robots are friendlier than some aggresive badly slept human doctors?;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";France;40-59;;;11/20/24
Fully agree;;Partly agree;But the unregulated use can lead to negative effects to consumers, as companies exploit the new got „unlimited“ human labor. (Like sale calls);Neutral;;Fully agree;;Partely agree;;Neutral;;Fully agree;;Information Technology;Austria;20-39;;;11/19/24
Fully agree;;Neutral;I think a right balance should it be - and trust to researchers;Partly agree;it depends highly on the context !!!;Fully agree;;Fully agree;yes;Partly agree;not sure if I understood the question correctly;Partly agree;independent oversight - by whom :-))) ;"Medicine; Artificial Intelligence; Research";UK;40-59;;;11/18/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Neutral;Are we looking just for the human health perspective or we also want to take in consideration the advances in technological development for AI? Innovation often comes from learning from erros, mistakes.;Partly agree;;Fully agree;;Research;Romania;20-39;;etele4sure@gmail.com;11/18/24
Fully agree;;Partly disagree;Some regulation is necessary, e.g. to avoid AI mistakes and dangers or discriminating AI models that have prejudices against certain individuals;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Austria;20-39;;;11/18/24
Fully agree;;Partly disagree;;Fully agree;;Fully agree;;Partely agree;;Partly agree;;Fully agree;;"Medicine; Research; Management; Public Authority; Decision-Making";India;20-39;;;11/18/24
Fully agree;;Neutral;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;;Austria;20-39;;;11/18/24
Fully agree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;France ;20-39;;;11/18/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Austria ;20-39;;;11/18/24
Fully agree;;Fully agree;;Partly agree;here I am not sure - sometimes a chatbot could be better today than a grumpy unwilling human;Fully agree;;Fully agree;assuming that you mean info overload;Fully agree;;Partly agree;I am not so sure - who should really be able to do such an oversight - can we?;"Medicine; Artificial Intelligence; Information Technology; Research; Management";France;40-59;;;11/18/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Moldavia;40-59;;;11/18/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;this is important topic;"Medicine; Artificial Intelligence; Information Technology";Poland;40-59;;;11/18/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Management";India;above 60;;;11/18/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Management";India;above 60;;;11/18/24
Fully agree;;Fully agree;;Fully agree;;Neutral;;Partely agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Australia;20-39;;ashkan.zadeh@qut.edu.au;11/18/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management; Decision-Making";Denmark;40-59;;;11/16/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Switzerland;40-59;;;11/14/24
Fully agree;yeah;Neutral;here I am not sure;Neutral;I am also not sure here;Fully agree;yes;Fully agree;yes;Neutral;I am not sure ;Fully agree;but who will do this independent oversight ???;"Medicine; Artificial Intelligence; Information Technology; Research";Germany;40-59;;;11/14/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Egypt;above 60;;;11/14/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Decision-Making";Luxembourg;above 60;;;11/14/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Partly disagree;;Neutral;;Partly agree;;"Artificial Intelligence; Research";Portugal;20-39;;;11/14/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Management";Ghana;40-59;;;11/14/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Research";Switzerland;above 60;;;11/14/24
Fully disagree;;Partly agree;;Fully agree;;Partly agree;;Partely agree;;Partly agree;;Partly disagree;;"Medicine; Research";Brazil ;20-39;;;11/14/24
Fully agree;;Fully agree;;Fully agree;;Fully disagree;;Neutral;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Portugal;20-39;;fer.carlosan@gmail.com;11/13/24
Fully agree;;Fully disagree;;Fully agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;Medicine;Brazil;20-39;;;11/13/24
Partly agree;Yes. But we are at early stages so technology will improve and humans make a lot of mistakes too.;Fully agree;;Fully disagree;When AI voice gets to impressive level of accuracy when compared to human voices, we will be comforted if provided accurate and reliable information by AI. Doctors lack empathy and their compassion at times is limited due to resource constraints. In many opportunities, patients are left, wondering what to do, where to go for information, and where to complain when they have an issue. The Canadian healthcare system certainly doesn’t support patients in multiple ways. With eight minutes that you have with a specialist, there is very little you can cover about your concerns and fears. AI will fill a lot of gaps. ;Fully agree;;Fully disagree;Who made this questionnaire? LOL! A I can modify the amount of information that you get so it can provide as much as you like or as little as you like. Also, trust in technology will grow and grow as we are on the very early stages of a transformative tool that will outsmart people.;Fully agree;;Partly agree;;"Artificial Intelligence; Decision-Making";Canada;40-59;;gagalala900@gmail.com;11/13/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";Switzerland;above 60;;;11/13/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;"Medicine; Management; Public Authority; Decision-Making";Schweiz;above 60;;;11/13/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Research";Canada;40-59;;vinod.chandran@uhn.ca;11/13/24
Fully agree;however, who is responsible =?=?;Neutral;I am not sure;Partly agree;also not sure;Fully agree;yes;Partely agree;maybe;Partly agree;is statistics not better than any human?;Partly agree;who makes this oversight - me?;"Medicine; Management; Public Authority; Decision-Making";Germany;above 60;;;11/13/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Management; Public Authority; Decision-Making";India;above 60;;;11/13/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Management";Germany;above 60;;;11/13/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Research";Canada;above 60;;;11/13/24
Partly agree;who is validating it?;Partly agree;can it still be regulated?;Partly agree;if you compare a chatbot with an angry doctor - who is more patient?;Partly agree;I did not understand what you mean here?;Partely agree;I do think you mean information-overload ?;Partly agree;I also do not 100 % agree on that;Partly agree;again, who can do the independent oversight, is this still possible? ;"Medicine; Artificial Intelligence; Information Technology; Management; Public Authority; Decision-Making";Germany;above 60;this is an important survey;;11/13/24
Fully agree;;Neutral;;Partly agree;;Fully agree;;Fully agree;;Neutral;;Fully agree;;Artificial Intelligence;India;20-39;;;11/13/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Neutral;;Fully agree;;Artificial Intelligence;Portugal;40-59;;luisft@fe.up.pt;11/13/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";Germany;40-59;;;11/13/24
Fully agree;;Partly agree;ich bin mir hier nicht sicher;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Germany;40-59;;;11/13/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";Germany;20-39;;;11/13/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";Germany;20-39;;;11/13/24
Partly agree;;Fully agree;;Partly agree;;Partly agree;;Neutral;;Partly agree;;Neutral;;"Artificial Intelligence; Management";Singapore;40-59;;;11/13/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partely agree;;Neutral;;Fully agree;;"Artificial Intelligence; Research";India;20-39;;;11/13/24
Fully agree;;Partly agree;;Partly disagree;;Fully agree;;Fully agree;;Partly agree;;Partly agree;;"Artificial Intelligence; Research";Portugal;20-39;;;11/12/24
Fully agree;It is worse than most people even realize;Fully agree;Especially when regulation is done by people who have little knowledge on the specific topic;Fully agree;It is not just dehumanization and empathy - the closed system would not react properly to new issues;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Canada;40-59;;;11/12/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Research";Portugal;20-39;;nunes.joaodiogo@gmail.com;11/12/24
Fully agree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Partly agree;;Partly agree;;Artificial Intelligence;Portugal ;20-39;;;11/12/24
Fully agree;;Partly agree;;Partly agree;At current AI state of the art, I agree with the statement.;Fully agree;;Fully agree;;Partly agree;"I agree, assuming that the ""individual patient circumstances"" are not part of the statistical models.";Neutral;;"Artificial Intelligence; Research";Portugal;40-59;;;11/12/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Research;Portugal;above 60;;;11/12/24
Fully disagree;;Fully disagree;;Partly disagree;;Fully disagree;;Fully agree;;Partly disagree;;Neutral;;"Artificial Intelligence; Information Technology; Research";Portugal;20-39;;mohammad.h.zolfagharnasab@inesctec.pt;11/12/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Partely agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Research";Portugal;20-39;;;11/12/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;;India;below 20;;;11/12/24
Fully agree;;Partly agree;;Fully disagree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Portugal;20-39;;;11/12/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Portugal;20-39;;tiago.galves@hotmail.com;11/12/24
Fully agree;;Neutral;;Partly agree;;Partly disagree;;Fully agree;;Partly agree;;Neutral;;"Artificial Intelligence; Information Technology; Research";Spain;20-39;;;11/12/24
Fully agree;;Fully agree;;Partly disagree;;Neutral;;Partely agree;;Partly agree;;Fully agree;;;Romania;40-59;;;11/12/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Switzerland;20-39;;;11/12/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management; Decision-Making";Germany;40-59;;;11/12/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";India;20-39;;;11/12/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research; Decision-Making";Germany;40-59;Sehr wichtige Umfrage!;;11/12/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Malaysia;40-59;;;11/12/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Italy;above 60;;carlo.combi@univr.it;11/11/24
Fully agree;;Partly agree;;Partly disagree;;Fully agree;;Partely agree;;Neutral;;Partly agree;;"Artificial Intelligence; Information Technology; Research";Austria;40-59;;;11/11/24
Fully agree;;Partly agree;;Partly agree;it depends. if it is an addtional support and I still contact with my doctor it can be a benefit but if it will replace the doctor, I fully agree;Fully agree;;Partely agree;;Fully agree;;Fully agree;;Research;India;40-59;;;11/11/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Deutschland;20-39;;;11/11/24
Fully agree;ja;Fully agree;würde ja sagen;Partly agree;möglicherweise ist ein robi einfühlsamer als ein ruppiger Doctor;Fully agree;da;Partely agree;abhängig - prinzipiell eher ja;Fully agree;ja;Partly agree;schon ja, aber wer denn bitte soll diesen ooversight denn heute noch haben?;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Deutschland ;40-59;;;11/11/24
Fully agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;hungary;above 60;;;11/11/24
Neutral;;Neutral;;Neutral;;Neutral;;Neutral;;Neutral;;Partly disagree;;Information Technology;USA;20-39;;;11/11/24
Neutral;;Partly agree;;Partly agree;;Partly agree;;Partely agree;;Partly agree;;Neutral;;Information Technology;Romania;20-39;;ioan_dumy@yahoo.com;11/11/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;România;20-39;;;11/11/24
Partly agree;;Fully agree;;Fully agree;;Neutral;;Fully agree;;Neutral;;Partly agree;;;USA;20-39;;;11/11/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research; Management";Austria;40-59;;mtmayrhofer@yahoo.de;11/11/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;Slovenia;20-39;;;11/9/24
Fully disagree;;Fully disagree;;Partly agree;;Partly disagree;;Partely agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Research";Romania;40-59;;catalin.stoean@inf.ucv.ro;11/8/24
Fully agree;;Fully agree;;Partly agree;;Fully agree;;Partely agree;;Neutral;It is possible that the statisitcal models would incorporate individual patient circumstances, so it is hard to evaluate this statement. ;Partly disagree;"Accountability can be independent of continuous human oversight. Just like robots in assembly lines do not need to be constantly monitored and second guessed by a human operator, or like the ""decisions"" of ABS sensors or distance sensors in cars do not need to run through a human monitoring to trigger an action, but if harm happens, accountability is possible to determine. The monitoring and approval of application for these systems should be regulated based on the scope of their application and the possible harm and risk of harm deriving from their decision making.
Similarly, transparency can still be an issue even if a human makes the final call. Interpretable AI should be a goal we strive for, and if we are able to achieve this goal, transparency can be guarantied (of course taking into account personal and sensitive data, which might limit transparency in any case, both with human-only, and with AI approaches).";"Artificial Intelligence; Research";Hungary;40-59;"I think many people will mis-interpret this survey.
The survey asks us to rate our agreement with the sentences, but I think many (or most?) people will answer based on how much risk/problem they see with the type of ""sin"".
Qualitative research might be needed to understand, what people mean by their responses. (I know that there is free-text response field, but probably a majority of people will not leave comments or explain their responses.)";kekecs.zoltan@gmail.com;11/8/24
Partly agree;;Fully agree;;Neutral;;Fully agree;;Partely agree;;Partly agree;;Fully agree;;Medicine;Hungary;40-59;;shenkerb@gmail.com;11/8/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Research; Management; Decision-Making";Hungary;above 60;;;11/7/24
Partly agree;;Partly agree;;Fully agree;;Neutral;;Partely agree;;Neutral;;Fully agree;;;India;20-39;;;11/7/24
Fully agree;;Partly agree;;Fully agree;;Neutral;;Partely agree;;Partly agree;;Partly agree;;Information Technology;Germany;40-59;;;11/7/24
Partly disagree;;Partly agree;;Fully agree;;Partly agree;;Partely agree;;Partly agree;;Partly agree;;Medicine;Hungary;above 60;;;11/7/24
Fully agree;;Partly agree;;Partly agree;I think combination of AI and in person medicine is the best way. AI could help doctors on those issues that are time-consuming, and usually hated by doctors (e.g. administrative tasks;Partly agree;;Partely agree;;Partly agree;;Partly agree;;Medicine;Hungary;above 60;thank you for asking. Good to know that this field is researched from this aspect (as well);varga.katalin@ppk.elte.hu;11/7/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Neutral;Partly disagree with the first part (AI systems that generate too much information), fully agree wiith (provide false predictions);Fully agree;;Fully agree;;;Hungary;above 60;;;11/7/24
Fully agree;;Fully agree;;Partly disagree;;Partly agree;;Partely agree;;Partly agree;;Partly agree;;;Hungary ;20-39;;;11/7/24
Fully agree;;Fully disagree;;Partly agree;;Partly agree;;Partely agree;;Partly agree;;Fully agree;;"Medicine; Research; Decision-Making";Hungary;40-59;;Szilidri@yahoo.com;11/7/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;Hungary;40-59;;;11/7/24
Fully agree;;Neutral;;Partly agree;;Partly agree;;Partely agree;;Neutral;;Partly agree;;Research;Hungary;40-59;;;11/7/24
Partly agree;;Neutral;;Partly agree;;Partly agree;;Partly disagree;;Neutral;;Partly agree;;Information Technology;Austria;20-39;;jakob.balassa@students.boku.ac.at;11/7/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Austria;40-59;;ruben.ruiz@imc.ac.at;11/6/24
Fully agree;absolut;Partly agree;nicht sicher;Partly agree;nicht sicher;Fully agree;absolut;Partely agree;hängt ab;Fully agree;absoluit;Partly agree;aber wer soll oversight machen?;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Germany;40-59;Danke an Professor Holzinger für seine Inspiration!;;11/6/24
Partly disagree;;Partly agree;;Partly agree;;Partly disagree;;Partely agree;;Partly agree;;Fully agree;;"Medicine; Research";India;40-59;;;11/5/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Partely agree;;Partly agree;;Fully agree;;;Austria;20-39;;;11/4/24
Fully agree;;Partly disagree;AI Act is a well needed regulation to increase trust in using AI system - yet it will increase the burden for researchers.;Partly disagree;;Partly agree;;Partely agree;Difficult to disagree on such a statement.. biased question;Partly agree;Difficult to disagree on such a statement.. biased question;Partly disagree;Depends on the level of testing and certification;Information Technology;Belgium;above 60;;isabelle@dezegher.com;11/3/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Partely agree;;Partly agree;;Partly agree;;"Artificial Intelligence; Information Technology; Research";Italy;40-59;;;11/3/24
Fully agree;yes;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Germany;40-59;;;11/3/24
Partly agree;While AI systems are not infallible, human doctors are also not infallible - there is always an inherent uncertainty - a solution could be to let work both together;Neutral;I partially agree with the statement. While excessive regulation can indeed stifle innovation, it's important to balance the need for progress with the imperative to ensure ethical and responsible AI development.;Fully agree;I fully agree with this statement. While AI systems can be incredibly useful tools in healthcare, they cannot fully replace the human touch and empathy that are essential for effective patient care.;Fully agree;This is a significant concern in healthcare, where complex factors like quality of life, patient satisfaction, and long-term health outcomes are often difficult to quantify;Fully agree;Overwhelming users with excessive information or providing inaccurate predictions can erode trust in AI systems, we call this information overload!;Fully agree;Patients can vary significantly in terms of genetics, lifestyle, and medical history. A one-size-fits-all approach based solely on statistical models may not be optimal for everyone.;Fully agree;A human-centered AI approach is essential!;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Germany;40-59;Thanks to Professor Holzinger for making me aware of this important survey, without him pointing to this I would not have filled this out ...;;11/1/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;Information Technology;India;40-59;;;10/30/24
Fully agree;;Partly disagree;;Fully agree;;Partly agree;;Partely agree;;Fully agree;;Partly agree;;"Artificial Intelligence; Research";Germany;40-59;;martina.philippi@uni-paderborn.de;10/30/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Management; Public Authority";Germany;40-59;;;10/30/24
Fully agree;;Partly disagree;;Fully agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;"Research; Decision-Making";India;20-39;;;10/29/24
Fully agree;;Fully agree;;Partly agree;Certainly, if the patient never gets to see a doctor and is only treated by AI systems. However, there might be (sub-)tasks where an AI would do a good job and could help to decrease the workload of doctors.;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Germany;20-39;;;10/28/24
Fully agree;;Partly agree;;Partly disagree;;Partly agree;;Partely agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Romania;40-59;;;10/28/24
Fully agree;Testing is important but it will need to involve domain experts and patient involvment to identify the risks and potential harms. Validation also needs to take into account the wider context of implementation into clinical processes.;Partly disagree;I don't think it's regulated enough but it needs better guidance on how to develop AI systems more responsibly.;Fully agree;I agree but I think we need to separate autonomy from AI systems. ;Partly agree;We need to figure out more about what good measures are, that align with patient outcomes. In research it is sometimes impossible to get at outcomes directly.;Partely agree;Yes, explanations need to be carefully contrsuted and assessed, as well as the risks of mispredictions need to be studied.;Neutral;Not sure about this. Depends on the task.;Fully agree;Yes, it needs a human to undertand how they work.;Research;United Kingdom;40-59;;;10/28/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Research;Germany;20-39;;;10/28/24
Partly agree;;Fully agree;;Partly agree;;Partly agree;;Partely agree;;Partly agree;;Partly agree;;"Artificial Intelligence; Research";Germany;40-59;;bwrede3@uni-bielefeld.de;10/26/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Deutschland, Stuttgart;40-59;;;10/25/24
Fully agree;is this not with all machines ?;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research; Management";Stuttgart, Deutschland;40-59;;;10/25/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Germany (Bielefeld Area);20-39;;;10/25/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Public Authority; Decision-Making";Germany;40-59;;;10/25/24
Fully agree;;Partly agree;;Fully agree;;Neutral;;Fully agree;;Fully agree;;Partly agree;;Research;Germany;20-39;;;10/24/24
Fully agree;;Fully agree;regulation stops progess in many fields - so also here;Neutral;I do not worry about that;Neutral;maybe statistics is better than gut-feeling?;Fully agree;too much information is always bad and hinders decison making - we know taht;Partly agree;maybe the solution is in both?;Fully agree;yes, but who has all the knowledge of doing so?;"Medicine; Artificial Intelligence; Information Technology; Research; Management; Decision-Making";Germany;above 60;;;10/24/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Germany;20-39;;;10/24/24
Fully disagree;;Partly agree;;Neutral;;Partly agree;;Fully agree;;Partly agree;;Partly agree;;"Medicine; Artificial Intelligence";Germany;20-39;;drimalla@uni-bielefeld.de;10/24/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;What type of metrics? I find this question too ambiguous;Fully disagree;;Partly agree;but it's possible that some statistical models could be developed to include patient circumstances to address these challenges;Fully agree;;"Artificial Intelligence; Research";Germany;40-59;I find this to be a very loaded survey. By framing these all as sins, you will get the answers you expect.  I think you should ask more neutral questions.;djohnson@techfak.de;10/24/24
Fully agree;;Partly disagree;Highly dependent on who decides about regulations and how exactly they look like.;Partly disagree;I used correctly, I am convinced they could even increase satisfaction, as the doctor has more time for interaction.;Partly disagree;"As long as the metric used matches the current patient, it is better to use a metric not aligning with ""the overall patient""";Partely agree;;Partly disagree;A good statistical model should cover relevant aspects (such as the patients circumstances) as well. ;Fully agree;;"Artificial Intelligence; Research; Decision-Making";Germany;20-39;;arobrecht@techfak.de;10/24/24
Fully agree;;Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";India;40-59;;;10/24/24
Fully agree;;Partly disagree;"The word excessive here confuses me. Sure, ""Excessive"" regulation is bad by definition, so my answer is more to the question ""Much regulation ....""";Partly agree;;Partly agree;Depends on what the system is designed to do.;Fully agree;;Fully agree;;Partly agree;;Artificial Intelligence;Germany;20-39;;jpaletschek@techfak.uni-bielefeld.de;10/24/24
Fully agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;Neutral;I do not understand this question. The statistical models should by themselves already account for patient circumstances;Fully agree;;"Artificial Intelligence; Information Technology";Germany;above 60;;;10/24/24
Fully agree;;Fully agree;;Partly disagree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Germany;20-39;;;10/24/24
Partly agree;;Fully disagree;;Partly disagree;Highly depends on the implementation of the system ;Partly agree;;Fully agree;;Fully agree;Shared-decision making is key, patients need to be a part;Fully agree;;"Artificial Intelligence; Information Technology; Research; Decision-Making";Germany;20-39;;;10/24/24
Fully agree;;Partly disagree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Research; Decision-Making";Germany;20-39;;;10/24/24
Fully agree;;Fully agree;;Neutral;;Neutral;;Fully agree;;Fully agree;;Partly agree;;Research;USA;above 60;;;10/24/24
Fully agree;;Partly agree;;Fully agree;;Partly agree;;Partly disagree;I feel this highly depends on the user group that is targeted and the training that they get in using and interpreting an AI system, especially as such a system is likely to be flawed in several ways wrt the task. For example, I would expect not anyone working in healthcare is supposed to operate an MRI machine, but a subset is trained to use one.;Neutral;Probably depends on the application;Partly agree;External oversight would probably be good as a stopgap in most cases, barring major advances in AI technologies;"Artificial Intelligence; Information Technology; Research";Germany;20-39;;rvisser@techfak.uni-bielefeld.de;10/24/24
Fully agree;That goes without saying, doesn't it?;Neutral;;Partly agree;I wouldn't focus on empathy and satisfaction, tht's why I agree only partly. AI/Informatics has a very (!) reduced understanding of what diagnosing means, and that has to be counteracted.;Fully agree;;Fully agree;;Partly agree;Depends on the context. When diagnosing an individual, obviously true.;Fully agree;;;Germany;40-59;;;10/24/24
Fully agree;;Partly disagree;Regulation is also about making knowledge action. Expertise and long term research is flowing into knowledge.;Partly disagree;Should AI systems replace some actions or really interaction and compassion?;Neutral;;Partely agree;;Fully agree;;Fully agree;;Research;Germany;40-59;;katharina.rohlfing@upb.de;10/24/24
Partly agree;;Partly disagree;;Partly agree;I would partly agree with the last part of this statement, since already patients express dissatisfaction for being treatment as a bureucratic profiles rather than a human being. Regarding AI systems, I think the chances are high for patients to feel not fully seen and cared for by AI systems, especially when the communication and explanations do not work out well. ;Fully agree;;Partely agree;;Partly agree;;Fully agree;;;Germany;20-39;;patrick.henschen@upb.de;10/24/24
Fully agree;;Fully agree;;Partly disagree;;Partly agree;;Partely agree;;Partly disagree;;Partly agree;;"Artificial Intelligence; Research";Germany;20-39;;;10/24/24
Fully agree;;Partly agree;;Neutral;;Partly agree;;Partely agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Germany;20-39;;philipp.terhoerst@uni-paderborn.de;10/24/24
Partly agree;depending on the design of the system, and quality of data;Partly disagree;depending on the type of regulation;Partly agree;;Partly agree;;Fully agree;;Partly disagree;statistical models could also account for that;Partly agree;;"Artificial Intelligence; Research";Germany;20-39;;;10/24/24
Fully agree;;Fully agree;;Partly agree;There is suitable design to prevent that ...;Partly agree;;Partely agree;Depends on expertise of human;Partly agree;;Partly agree;;"Artificial Intelligence; Research";Germany;40-59;;;10/24/24
Fully agree;;Partly disagree;"Why ""could"" but ""Sin 1"" uses ""can""? Many things ""could"" happen but are neither likely nor important.";Partly agree;Assuming that there is such a thing as compassion in the patient-doctor relationship and not just stress and economic pressures.;Fully disagree;"Do not understand what ""overall patient outcomes"" means.";Fully agree;;Fully agree;"That does not mean that ""AI-free"" decisions do consider individual patient circumstances. Often they do not either.";Fully agree;;"Information Technology; Research";Germany;40-59;;;10/24/24
Fully agree;;Partly disagree;;Neutral;The patient-doctor relationship is often already abysmal even without AI systems. Many doctors already lack empathy.;Fully agree;;Partely agree;;Partly agree;;Partly agree;;"Medicine; Artificial Intelligence; Research";Germany;20-39;;;10/24/24
Fully agree;we must stop playing with A.I.;Partly disagree;There should be excessive regulation to make sure people don't make hazzardous behaviours has seen in other parts of the world, such as control the population or mistakes that could endanger indiciduals. Nevertheless, there should be guidance concerning this.;Neutral;Patient-doctor relashionships are not good most of the times. A.I. should support people to be more human and compassionate in interactios/workload.;Partly disagree;Metrics should be restructured, the outcome should be patient and professional satisfaction, metrics should provide this, not accuracy;Neutral;There are A.I. systems and A.I. systems, some well made others not. Labeling A I. is not samething that makes sence to me, because there is a lot of A.I., different datasets and different ways to make it. Some areas are more developed than others, so this does not make sense to me. Also Ai.I. does not to be trusted if it only gives a suggestion;Neutral;Depends on how you build it;Partly agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management; Decision-Making";Portugal;40-59;I am an expert in Responsible AI;david.belo@safe-ai-4u.eu;10/24/24
Fully agree;Who teaches artificial intelligence? AI can collect all kinds of information.;Partly agree;Controlled experiments are needed.;Neutral;It depends on the patient's problem.;Neutral;;Fully agree;;Fully agree;;Fully agree;;Information Technology;Hungary;above 60;;;10/23/24
Fully agree;;Partly disagree;;Fully agree;;Neutral;not certain that I got the gist of the question;Partely agree;proper introduction of the inner workings of implemented technology  necessary beforehand ;Fully agree;;Fully agree;;;India;20-39;;;10/23/24
Partly disagree;;Fully agree;;Fully agree;;Neutral;;Partely agree;;Partly agree;;Partly disagree;;"Artificial Intelligence; Information Technology; Research";Hungary;20-39;;;10/23/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Research";Germany;20-39;;;10/23/24
Fully agree;;Partly agree;I think we need a balanced approach;Neutral;it depends - I see AI only as a tool;Fully agree;big danger!!!;Fully agree;yes, as a doctor I cannot process more and more information - it is a nightmare;Partly agree;depends;Partly agree;"but who really should have this ""oversight""? doctors? ";"Medicine; Artificial Intelligence; Management; Decision-Making";Germany;40-59;;;10/23/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Partely agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Research";India;20-39;;;10/22/24
Fully agree;who would not agree here;Neutral;do not know ;Partly agree;maybe sometimes an AI can be better?;Fully agree;yes;Neutral;it depends on the knowledge of the doctor;Fully agree;yes;Partly agree;I am not sure;"Medicine; Artificial Intelligence; Information Technology; Research";Germany;20-39;;;10/22/24
Partly agree;;Partly agree;;Fully agree;;Partly disagree;;Partely agree;;Fully agree;;Fully agree;;;Austria ;below 20;;;10/22/24
Neutral;;Partly agree;;Fully agree;;Partly agree;;Neutral;;Partly agree;;Fully agree;;;Italy;20-39;;;10/22/24
Partly agree;Blind reliance on unitary humans (e.g. just one doctor) without appropriate checks often has the same effect.;Fully agree;Balance is always needed, although tough to achieve ;Partly agree;;Fully agree;;Partely agree;The amount of information produced by AI systems can be controlled and even tailored to user preferences, which is not always the case with humans. False predictions though would have detrimental effects on trust;Neutral;Even when relying on statistical models that are primarily trained on a multitude of cases, AI systems are more adept to personalising predictions, if the system is engineered tht way. ;Fully agree;;"Artificial Intelligence; Decision-Making";Greece;40-59;;;10/22/24
Fully agree;;Fully agree;;Fully agree;;Neutral;;Partely agree;;Partly agree;;Partly agree;;"Artificial Intelligence; Research";The Netherlands;20-39;;;10/22/24
Fully agree;Current AI capabilities demand more than a cursory review ;Fully agree;"Emphasis on ""Excessive"" ";Partly disagree;It could, but some studies have shown an increased sense of empathy, compared to busy or overfworked clinicians. https://jamanetwork-com.ezproxy.cul.columbia.edu/journals/jamanetworkopen/fullarticle/2821167#google_vignette;Partly disagree;"Sometimes metrics that aren't clinically relevant can help predict patient outcomes. Such is the promise of ""Big Data""";Fully agree;;Fully agree;;Fully agree;;Medicine;USA;20-39;;azizalkattan@gmail.com;10/21/24
Partly agree;;Fully agree;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;;Brazil;below 20;;;10/21/24
Fully agree;;Partly agree;;Partly disagree;;Fully agree;;Partely agree;;Neutral;;Fully agree;;"Medicine; Artificial Intelligence; Research";Brazil;20-39;;franko.hrzic@childrens.harvard.edu;10/21/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Brazil;20-39;;;10/21/24
Fully disagree;;Partly agree;;Fully agree;;Neutral;;Partely agree;;Fully agree;;Fully agree;;;Brazil;20-39;;;10/21/24
Fully disagree;;Partly agree;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";Brazil;above 60;;;10/21/24
Fully agree;;Partly agree;;Fully agree;;Partly disagree;;Fully agree;Fully agree on the false predictions - this statement should be broken down into two different ones. One for too much information and another on false predictions.;Fully agree;;Partly agree;;"Artificial Intelligence; Information Technology; Research; Decision-Making";United Kingdom;20-39;;dpiotogiannaki@gmail.com;10/21/24
Partly agree;;Partly disagree;;Neutral;;Fully agree;;Partely agree;;Partly agree;;Partly agree;;;Austria;20-39;;;10/21/24
Partly agree;;Neutral;;Neutral;;Partly agree;;Partely agree;;Neutral;;Neutral;;Research;Austria;20-39;;mateo.stoeckl@stoeckl.com;10/21/24
Fully agree;;Partly agree;;Neutral;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;Research;Vienna;20-39;;tim.halbgebauer@gmail.com;10/21/24
Fully agree;;Partly disagree;;Neutral;;Partly agree;;Partely agree;;Fully agree;;Fully agree;;Research;Austria;20-39;;amilresidbegovic@outlook.com;10/21/24
Partly agree;;Partly disagree;;Fully agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;Research;Brazil;20-39;;gerli1789@gmail.com;10/21/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Neutral;;Fully agree;;Neutral;;;USA;20-39;;;10/21/24
Partly agree;;Partly agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Germany;20-39;;;10/21/24
Fully agree;;Partly agree;;Fully agree;;Partly agree;;Partely agree;;Neutral;;Neutral;;;Austria;below 20;;;10/21/24
Fully agree;;Neutral;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;;Luxembourg;20-39;;aliciaweinandy@gmail.com;10/21/24
Fully agree;;Neutral;;Partly agree;;Neutral;;Fully agree;;Neutral;;Partly agree;;Research;Italy;below 20;;;10/21/24
Fully agree;;Fully agree;;Partly agree;;Neutral;;Partely agree;;Fully agree;;Partly agree;;;Austria;20-39;;;10/21/24
Partly agree;;Partly agree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;;Brazil;below 20;;;10/21/24
Fully agree;;Fully agree;;Partly disagree;Doctors are often tired after a long shift or work only for money. They can loose the empathy and compassion very quick in a normal hospital job. AI could be less biased than doctors in this sense. ;Fully agree;Alignment with expert knowledge of medical doctors can be useful. ;Fully agree;;Neutral;"It is hard to tell if in a realistic case doctors really take these 'individual patient circumstances' into account. They usually only try to follow their gut (e.g. use therapy/drug A instead of 
B), which might lead to incorrect or inappropriate decision making as well. ";Fully agree;AI should empower humans, not automate the very complex job. ;"Artificial Intelligence; Research";Poland;20-39;Good survey. I want to point out that the need for AI-based decision making can be drastically different in 3rd world countries where the quantity of good doctors is rather scarce. As opposed to US or EU. ;h.baniecki@uw.edu.pl;10/21/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research; Management; Decision-Making";Germany;40-59;;;10/21/24
Fully agree;100 % yes;Neutral;I am not sure;Partly disagree;I am not sure - maybe some AI is friendlier than a human doctor?;Fully agree;yes;Neutral;not sure here too;Fully agree;yes;Neutral;who will do the oversight? can a human do that in the future?;"Artificial Intelligence; Information Technology; Research; Management";Germany;above 60;;;10/21/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Management";Germany;20-39;;;10/21/24
Fully agree;;Fully agree;;Neutral;is this not the opposite ??;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Brazil;above 60;;;10/20/24
Partly agree;;Partly agree;;Partly agree;;Neutral;;Partly disagree;;Fully agree;;Neutral;;;USA;20-39;;;10/20/24
Fully agree;;Neutral;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;"Medicine; Research";Sweden;40-59;I am a registered nurse by background;hanna.allemann@liu.se;10/20/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Italy;40-59;;paolo.buono@uniba.it;10/19/24
Fully agree;validation is a fundamental scientific principle in every domain !!;Fully agree;Stop doing AI research would not help to stop dangers;Neutral;Sometimes computer systems behave better than some strange humans - think that not all people can also be deliberately hostile;Neutral;I am not sure if I really understand this question;Fully agree;It is a misunderstanding that more information helps to make better decisions as we now ;Neutral;I remember that the hype was on personalized medicine - does this fit in here as well? I do not know;Neutral;I am also unsure about this - maybe computers are more neurtral than some aggressive humans? I do not know.;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Deutschland;above 60;;;10/19/24
Fully agree;;Partly disagree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Research;USA;40-59;;;10/19/24
Fully agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;Italy;40-59;;omayora@fbk.eu;10/18/24
Fully agree;;Partly disagree;;Neutral;;Fully agree;;Fully agree;;Partly disagree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Brazil;20-39;;;10/18/24
Neutral;Need to be defined;Neutral;Fuftyfufty;Fully disagree;Ai is better than some doctors! ;Fully agree;Yes;Partely agree;Deoends;Fully agree;;Partly agree;How? ;"Artificial Intelligence; Information Technology; Management; Decision-Making";Germany;40-59;;;10/18/24
Partly agree;;Fully agree;;Fully agree;;Partly agree;;Partely agree;;Fully agree;;Partly agree;;;USA;;;;10/18/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;And also the seduction that AI is always right and reducing appropriate critical thinking ;Fully agree;;Fully agree;;Medicine;Australia ;above 60;;drterryhannan@gmail.com;10/18/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Decision-Making";Germany;40-59;;;10/17/24
Fully agree;;Fully agree;;Fully disagree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Medicine;Brazil ;40-59;;klebersaraujo@gmail.com;10/17/24
Fully agree;verification is always important;Neutral;we need a trade-off;Neutral;some doctors may be unfriendly;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Czech Republic;20-39;;;10/17/24
Fully agree;this is sure;Neutral;here i am not sure therefore Neutral;Partly agree;I am unsure a bit here - but tend towards partly agree;Fully agree;yes;Neutral;this depneds - I am unsure;Fully agree;yes;Partly agree;agree, but is a human able to do so?;"Artificial Intelligence; Information Technology";Czech Republic;20-39;I was inspired by Professor Holzinger, and must say that this is really a great survey;;10/17/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;great initiative!;"Artificial Intelligence; Information Technology; Research";India;20-39;;;10/17/24
Fully agree;AI needs to be used under the supervision of a Clinician ;Partly agree;But AI in Medicine is different to other feilds;Partly agree;It has to be used along with a clinician and not alone ;Partly agree;;Fully agree;;Fully agree;;Partly agree;;"Medicine; Information Technology";Sri Lanka;40-59;;gumindu@gmail.com;10/17/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Partely agree;;Fully agree;;Partly agree;;"Medicine; Artificial Intelligence; Management; Public Authority";Germany;40-59;;;10/17/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management";Indonesia;40-59;;;10/16/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";Czech Republic;20-39;I was inspired by the lecture given by Professor Holzinger! Thanks a lot!;;10/16/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";Czech Republic;20-39;;;10/16/24
Fully agree;it's crucial to carefully validate and verify AI systems before deploying them in critical applications;Partly agree;a well-balanced approach to regulation is essential for promoting responsible AI development while allowing for innovation and progress.;Fully agree;it is essential to maintain a strong focus on human-centered AI to ensure the best possible outcomes for patients;Fully agree;yes;Neutral;I think information overload is a problem generally ! A collaborative approach between doctors and AI systems is essential to ensure the best possible patient outcomes.;Fully agree;should be used in conjunction with human judgment and expertise, taking into account individual patient circumstances;Neutral;but who is able to do such oversight???;"Artificial Intelligence; Information Technology; Research";Poland;20-39;;;10/16/24
Fully agree;;Fully agree;;Partly disagree;There is evidence that, when used appropriately, AI systems can enhance the perceived empathy of doctor-patient communication (see e.g. Kearns et al. Proc AMIA Annu Symp '24, and work from Tim Althoff's group led by Ashish Sharma). This wouldn't be replacing human interaction, but does indicate the potential to augment it. ;Partly agree;There is a caveat that it may be possible to bridge from standard metrics of accuracy to effects on patient care, by extrapolating to metrics of utility for patient care (e.g. quantifying the tradeoff between FP and FN results). ;Partely agree;Although, there is evidence that additional information provided in the form of explanations can lead to increased trust in *false* predictions (https://dl.acm.org/doi/10.1145/3411764.3445717).;Partly agree;This could occur in the absence of a responsible clinician to interpret the predictions from a model in context - but I don't think many would advocate for autonomous AI medical decision makers at this point. ;Fully agree;;"Artificial Intelligence; Information Technology; Research";USA;40-59;;;10/16/24
Fully agree;yes;Neutral;not so sure;Partly disagree;humans can also be brutal or unsympathic!!;Fully agree;yes;Neutral;what is overinfroming - it depends on the expert status - student - 60years doctor - ?;Partly agree;sometimes statics can be right -better thana  a doctor;Neutral;CAN a human oversight it still ???;"Artificial Intelligence; Information Technology; Research";Czech Republic;20-39;really cool - this is totally important !!!;;10/16/24
Fully agree;;Fully disagree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;Information Technology;Austria;20-39;;;10/16/24
Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;Partly agree;;Research;Austria;20-39;;;10/16/24
Neutral;;Neutral;;Neutral;;Neutral;;Neutral;;Neutral;;Neutral;;;USA;20-39;;;10/16/24
Fully agree;;Neutral;;Partly agree;;Fully agree;;Neutral;;Fully agree;;Partly disagree;;;Austria;20-39;;;10/16/24
Fully agree;;Fully agree;;Partly agree;;Neutral;;Partly disagree;;Fully agree;;Fully agree;;Research;Austria;20-39;;gabriek.kothbauer@gmail.com;10/16/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;aligning is essential;Fully agree;fake news can easily be spread;Neutral;;Fully agree;;Research;Austria;below 20;;;10/16/24
Partly agree;;Partly agree;;Partly agree;;Partly agree;;Fully agree;;Neutral;;Partly agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Management; Public Authority; Decision-Making";russia;below 20;brutal one;;10/16/24
Partly agree;;Fully agree;;Fully agree;;Partly agree;;Partely agree;;Fully agree;;Neutral;;;USA;20-39;;;10/16/24
Partly agree;;Partly disagree;;Fully agree;;Partly agree;;Partely agree;;Fully agree;;Fully agree;;"Research; Decision-Making";Austria;20-39;;;10/16/24
Fully agree;;Partly disagree;;Partly agree;;Neutral;;Fully agree;;Partly agree;;Fully agree;;Research;Austria;40-59;;;10/16/24
Partly agree;;Partly disagree;;Fully agree;;Partly agree;;Fully agree;yes, definitiv;Partly agree;;Fully agree;;Research;Italy;below 20;;;10/16/24
Fully agree;ja das glaube ich;Neutral;;Neutral;;Fully agree;;Fully agree;;Neutral;;Neutral;;Research;USA;20-39;;;10/16/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;Research;India;below 20;;;10/16/24
Fully agree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;Research;Germany;below 20;;;10/16/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;Durchaus möglich aber lösbarer als andere Fragen im Bereich der KI.;Fully agree;;Fully agree;;Fully agree;;Research;Austria;20-39;Die Tatsache, dass wir Ihre Antworten sehen können verfälscht sicherlich die Ergebnisse, aber das wissen Sie natürlich selbst.;;10/16/24
Fully agree;;Partly agree;;Neutral;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;Research;Germany;20-39;;;10/16/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;Research;Germany;20-39;;;10/16/24
Fully agree;;Partly agree;;Fully disagree;;Partly agree;;Partely agree;;Neutral;;Fully agree;;;India;20-39;;;10/16/24
Fully agree;;Partly agree;;Partly agree;;Neutral;;Neutral;;Partly agree;;Neutral;;Research;Austria;20-39;;;10/16/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;Research;India;20-39;;;10/16/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;Research;India;20-39;;;10/16/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;Es kommt bei AI auf das Ziel an und damit entscheidet eine Person die die AI einstellt, über Leben und Tod;Research;Austria;20-39;;;10/16/24
Fully agree;;Partly agree;;Neutral;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;;India;20-39;;;10/16/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;Research;Germany;below 20;;;10/16/24
Fully agree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;;India;20-39;;;10/16/24
Partly agree;Man sollte nichts blind vertrauen. Ein gewisses Maß an kritischen Denken ist wichtig.;Partly agree;;Fully disagree;Bots cant replace empathy wich is important for the healing process;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Austria;20-39;very good very nice;;10/16/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;Research;Germany;below 20;;;10/16/24
Partly agree;;Partly agree;;Partly disagree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;Research;India;20-39;;;10/16/24
Fully agree;;Neutral;;Partly agree;;Partly agree;;Fully agree;;Neutral;;Neutral;;Research;USA;20-39;;;10/16/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Partely agree;;Partly agree;;Fully agree;;;India;below 20;;;10/16/24
Fully agree;ja das glaube ich;Partly agree;regulierung ist notwendig, aber nicht über den Hausverstand;Neutral;es kommt drauf an;Fully agree;aligment with patient outcomes is essential for me;Fully agree;ja definitiv;Partly agree;begrenzt;Fully agree;human oversight is essential for me personally;"Artificial Intelligence; Information Technology; Research";Austria;40-59;war ein cooler Fragebogen;;10/16/24
Fully agree;;Neutral;"ohne Regulierung ist eine Katastrophe vorprogrammiert; Regulierung wird aber durchaus einige negative Auswirkungen auf die Forschung haben";Fully agree;;Fully agree;;Fully agree;AI sollte im Normalfall nur Wahrscheinlichkeiten angeben und nicht definitive Ergebnisse;Fully agree;Hier ist selbstverständlich eine persönliche Abwägung erforderlich;Fully agree;;Research;India;20-39;;;10/16/24
Partly agree;Ai is, especially the not so advanced versions, can (if not checked) and will give false information (not on purpose). Its better used as a clever google and for basic summaries;Fully agree;Progress can NOT be stopped, it should be regulated to not cause to much harm, current models (neural networks) are not going to be very harmful. it is not artificial intelligence but just clever. it can only do what others tell it ;Fully agree;Can and will, humanity is becoming more and more lonely and the internet radicalises everyone against each other. everyone is fearful because of the countless cases of crimes heard. AI can give an illusion (should it become alot better) of compassion and interaction.;Partly agree;can happen cant tell;Fully agree;absolutely;Partly agree;"can. however a human can do that to if he is in a good/bad mood or has a good/bad heart.
I would argue it can happen but humans do this mistakes alot";Fully agree;can happen. still i would say that you can clearly ask the ai what it thinks. human oversight should still be applied;;Austria;20-39;I am not an expert but i did get better insight on those systems.;;10/16/24
Partly agree;;Partly agree;;Fully agree;;Neutral;;Partely agree;;Neutral;;Partly agree;;Research;Germany;below 20;;;10/16/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Partely agree;;Fully agree;;Neutral;;Research;Germany;20-39;;;10/16/24
Fully agree;;Partly agree;;Partly disagree;Sollten nicht ersetzt werden, da AI keine Gefühle wahrnehmen kann;Partly agree;;Fully agree;;Partly agree;Ausreißer werden nicht berücksichtigt;Fully agree;;;Austria;below 20;;;10/16/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Neutral;;Partly agree;;Fully agree;;;India;below 20;;;10/16/24
Fully agree;;Partly agree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;Research;Austria;20-39;;;10/16/24
Partly agree;;Fully agree;;Neutral;deppends;Fully agree;;Fully agree;;Fully agree;;Fully agree;human oversight is essential;;Austria;below 20;;;10/16/24
Fully disagree;;Partly agree;;Neutral;;Partly agree;;Fully agree;;Neutral;;Fully agree;;Research;India;20-39;;;10/16/24
Fully agree;;Partly agree;;Partly disagree;;Fully agree;;Fully agree;;Partly disagree;;Fully agree;;Research;Italy;20-39;;;10/16/24
Partly disagree;;Partly disagree;;Fully disagree;;Partly disagree;;Fully disagree;;Fully disagree;;Partly disagree;;Research;Austria;20-39;;;10/16/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partely agree;;Partly agree;;Fully agree;;;India;below 20;;;10/16/24
Partly agree;;Fully agree;;Partly agree;;Partly agree;;Fully agree;;Neutral;AI may have more time for the patient;Partly agree;;"Research; Management";Austria;20-39;;;10/16/24
Fully agree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;austria;20-39;;;10/16/24
Partly agree;;Partly agree;;Neutral;;Partly agree;;Fully agree;;Partly disagree;;Neutral;;Research;USA;20-39;;;10/16/24
Partly disagree;;Neutral;;Fully agree;;Neutral;;Partely agree;;Partly agree;;Fully agree;;Research;India;below 20;;;10/16/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;India;20-39;;;10/16/24
Partly disagree;;Partly agree;;Partly agree;;Partly agree;;Partely agree;;Partly agree;;Fully agree;;Research;India;20-39;;;10/16/24
Fully agree;;Fully disagree;;Partly agree;;Fully agree;;Partly disagree;;Partly disagree;;Fully disagree;;Information Technology;Austria;20-39;;;10/16/24
Fully disagree;;Partly agree;;Partly agree;;Neutral;;Partely agree;;Fully agree;;Fully agree;;Public Authority;Austria;40-59;;;10/16/24
Fully agree;;Partly agree;;Neutral;;Neutral;;Partely agree;;Neutral;;Neutral;;;India;20-39;;;10/16/24
Fully agree;;Partly disagree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;India;20-39;;;10/16/24
Fully agree;;Partly agree;"Define ""excessive"" ;-)";Partly agree;;Partly agree;;Partely agree;;Fully agree;;Fully agree;;"Information Technology; Management; Decision-Making";Austria;40-59;;;10/16/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Fully agree;;Partly agree;;Partly agree;;Decision-Making;Austria;20-39;;;10/16/24
Fully disagree;;Neutral;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Partly agree;;;USA;below 20;;;10/16/24
Partly agree;;Partly disagree;;Fully agree;;Partly agree;;Partely agree;;Fully agree;;Fully agree;;;India;below 20;;;10/16/24
Partly disagree;;Partly disagree;;Fully disagree;;Neutral;;Fully disagree;;Partly agree;;Neutral;;Research;Austria;20-39;;;10/16/24
Partly agree;;Fully agree;;Partly disagree;;Fully agree;;Partely agree;;Fully agree;;Partly disagree;;;Austria;20-39;;;10/16/24
Fully agree;;Fully disagree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;India;20-39;;;10/16/24
Fully agree;;Neutral;;Neutral;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;;Germany;20-39;;;10/16/24
Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Management;India;20-39;;;10/16/24
Partly agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Neutral;;;Austria;20-39;;jonas.huber20@gmail.com;10/16/24
Partly agree;;Partly disagree;;Fully agree;;Partly disagree;;Neutral;;Partly agree;;Fully agree;;;India;20-39;;;10/16/24
Fully agree;;Neutral;;Neutral;;Partly agree;;Neutral;;Neutral;;Neutral;;"Artificial Intelligence; Information Technology; Research";USA;40-59;;;10/16/24
Fully agree;Final decision must rest with the person;Fully agree;It is kind of a balancing act that should be iteratively achieved.;Partly agree;Traditional doctors practice by touching and they fill kind of usurped power;Fully agree;systems must add value to patient outcomes and experiences;Neutral;Only if it is not managed well;Fully agree;A systems approach is required and must include human beings. Of course silo mentality does not thrive in the AI era.;Fully agree;AI and robots should never be allowed to practice medicine independently;"Artificial Intelligence; Information Technology; Research; Management; Decision-Making";Botswana;above 60;;benson.ncube@gmail.com;10/16/24
Partly agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Information Technology; Management";India ;40-59;;;10/16/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";India;20-39;;;10/16/24
Fully agree;;Partly agree;debattable;Partly agree;depends;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Management";India;40-59;;;10/16/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";India;20-39;very good - thanks to Prof.Holzinger;;10/16/24
Partly agree;;Fully agree;is stifling innovation ;Fully disagree;Dont think doc patient relationship will be hampered as all of these will be at the backend ;Partly disagree;;Partly disagree;;Partly agree;;Partly agree;;Artificial Intelligence;India;40-59;;;10/16/24
Fully agree;;Partly agree;deepents;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology";Czech Republic;20-39;;;10/16/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";India;20-39;;;10/16/24
Fully agree;absolutely;Neutral;difficult;Partly disagree;sometimes AI is BETTER than humans;Fully agree;yea;Neutral;I woud not bet on that;Partly agree;difficult;Partly disagree;who will oversight such complicated systems????;"Artificial Intelligence; Information Technology; Research";Czech Republic;40-59;great talk by Professor Holzinger - thanks for introducing us these topics;;10/16/24
Partly agree;;Neutral;Unsure on how AI can be regulated;Partly disagree;AI systems actually behave more human and are generally kinder than most human interactions ;Partly agree;Still have to understand;Neutral;;Partly agree;The depth of the statistical test is deeper but the issue of distorted statistics themselves is better solved by AI systems ;Neutral;;"Medicine; Information Technology; Research";India;above 60;AI is a great equalizer - can bring up the contributions of these below average, but as yet cannot score over those who are real experts;gogia7@gmail.com;10/16/24
Fully agree;AI systems need adequate validation and verification before deployment, and once deployed - specifically for AI tools which have a machine learning component to manage data drift. There are methodological challenges which need to be monitored by skilled data scientists - but working closely with end users (clinicians) to inform;Partly agree;Regulation needs to support a system which can innovate and keep patients safe and do no harm. As with non tech interventions/innovation (eg medications) there is the risk of adverse events and harm - but there needs to be a model developed for AI tools too;Fully agree;;Fully agree;;Partely agree;;Partly disagree;;Fully agree;;Research;UK;40-59;;alisha.davies@wales.nhs.uk;10/15/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Research; Management; Decision-Making";Botswana;20-39;;;10/15/24
Fully disagree;;Neutral;;Fully disagree;;Partly disagree;;Fully disagree;;Partly disagree;;Fully disagree;;"Medicine; Research; Management; Decision-Making";USA;40-59;;;10/15/24
Partly agree;;Neutral;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Management;USA;20-39;;;10/15/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Ghana;40-59;;;10/15/24
Partly disagree;If the AI is provably reliable, the risk is controllable, then it should be okay to rely on the AI even with small acceptable risk. It just has to be economically feasible.;Fully agree;Regulation is always holding innovation back. Unfortunately there is not better solution. We have to have some control over it.;Fully agree;;Fully agree;;Fully agree;;Fully agree;The solution is to very carefuly define the domain of the model expertise and not use it for decision making that requires to assess information the model cannot process.;Partly disagree;The model is a tool. If you want to talk about accountability, you have to first decide how to approach the AI mdoels themselves, give them rights etc. This is not really possible. Until the models are self-aware and present their own goals and motivations that can be used as leverage on their functioning, we cannot talk about their accountability.;"Artificial Intelligence; Information Technology; Research; Management";Czech Republic;20-39;;adambajger@mail.muni.cz;10/15/24
Fully agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Information Technology;Czech Republic;20-39;;danishiqbal547@gmail.com;10/15/24
Fully agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;"Information Technology; Research; Decision-Making";Czech Repoublic;40-59;;anna.winklerova@mail.muni.cz;10/15/24
Fully agree;;Partly agree;;Neutral;;Neutral;;Partely agree;;Partly disagree;Make individual circumstances a part of the statistics;Partly agree;;"Artificial Intelligence; Information Technology";USA;20-39;;;10/15/24
Partly agree;Depends on applications, e.g. NPCs in games are quite harmless VS detection of malign tissue;Neutral;;Partly disagree;Replacemen is bad. But usually doctors also guess a lot. Do not replace humans, but sometimes replace the decision making.;Fully agree;;Fully agree;;Partly agree;Still they can perform better than humans in some cases.;Fully agree;;"Information Technology; Research";Czech Republic ;20-39;;;10/15/24
Fully agree;;Fully agree;;Partly disagree;;Fully agree;;Partely agree;;Partly agree;;Partly disagree;;"Artificial Intelligence; Information Technology; Research";USA;20-39;;chentenial@gmail.com;10/15/24
Fully agree;;Fully agree;;Neutral;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Information Technology;Czech Republic;20-39;;yasirdemircan@gmail.com;10/15/24
Fully agree;;Fully agree;;Partly agree;;Neutral;;Fully agree;;Partly agree;;Partly agree;;"Artificial Intelligence; Information Technology";Czech Republic;20-39;;;10/15/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Decision-Making";Czech Republic;20-39;;jan.kretinsky@gmail.com;10/15/24
Fully agree;;Partly agree;;Partly disagree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research";USA;40-59;;popelucha@gmail.com;10/15/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Fully agree;;Partly agree;;Partly agree;;"Artificial Intelligence; Information Technology";Korea;20-39;;;10/15/24
Fully agree;;Partly agree;;Neutral;;Partly agree;;Neutral;;Partly agree;;Fully agree;;;USA;;;;10/15/24
Fully agree;;Partly agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;40-59;;;10/15/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Research";Germany;20-39;;;10/15/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Austria;20-39;;;10/15/24
Partly agree;Should be a support system to automate the mundane, not a decision maker. AI can offer differential diagnosis, not decide on a definitive.;Neutral;Nothing like a lead weight to slow down innovation. Regulate areas where it possibly going to cause an issue, but need an education component which is just as important as the governance. Why are researchers and developers pushing they risk, when they don't carry the responsibility? Should be the end user collaborating with the developers. Don't design a product and try to squeeze it in to a niche. Identify the problem and the interface, then look at the experiment and solution to address it. ;Partly disagree;Depends on the setting. Have you met 50% of medical consultants? Empathy was lost the day they became consultants. 80/20 rule applies in medicine too. 20% of the staff are exceptional, the other 80% are quite average and sometime terrible. ;Partly agree;Different setting have different metrics. Are they clinical, executive, administrative or patient decided outcomes? Many non-clinical patient interactions can result in suboptimal outcomes (lost bookings, overbookings, missed referrals, waiting lists). ;Fully agree;More data is not better. Better data is important. Need to know what they data is before casting a net. ;Partly agree;"It is just a matter of having robust enough models with enough variables in the training. 
The final decision should not be based on the model, it should only act as a compass. Otherwise we lose the need for credentialled medical staff. ";Fully agree;Black box of decision making is no longer acceptable. Developers and researchers need to be transparent and use layman terms. If you can't explain it in 25 words, then you don't understand it either!;"Medicine; Information Technology; Research";Australia;40-59;;;10/15/24
Fully agree;Any computer-based system should be thoroughly validated/verified before it can be put into use. This definitely applies to AI systems even if their decisions would subsequently be vetted by the human users.;Partly disagree;"Research should be facilitated through appropriate, and not constraining regulations; however moving from the research laboratory to approved use is a different stage demanding regulations that guarantee safe and trustworthy deployment of the research results.";Fully agree;The patient-doctor relationship should be strengthened and not undermined by the use of AI systems. Synergy between all entities (doctors, patients, AI systems) should be the way forward.;Fully agree;The goal should be for the continuous improvement of patient outcomes and decision making should be aligned towards this goal and against the maximization of metrics that are not likewise aligned.;Partely agree;"Too much information as long as it is relevant and appropriate to its context is not bad and thus should not decrease trust in the technology or create confusion. Likewise if false predictions are not frequent and could be justified, these should not necessarily decrease trust. Everything is relevant and not absolute; after all humans' problem solving is not infallible and the analysis of a mistake is multidimensional. ";Partly agree;"Statistics are useful but to a certain extent; a statistical prediction, may not necessarily lead to an incorrect or inappropriate decision, but statistics should be coalesced with an individual patient's circumstances.  ";Fully agree;External, independent, and transparent evaluation is necessary. ;"Artificial Intelligence; Research";Cyprus;above 60;This is an interesting survey and accompanied paper. Thank you!;elpida@ucy.ac.cy;10/14/24
Fully disagree;;Partly agree;;Partly disagree;;Fully agree;;Neutral;;Partly agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";USA;above 60;;hersh@ohsu.edu;10/14/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Partly disagree;;Partly agree;;Partly agree;;"Information Technology; Research";UK;40-59;;;10/14/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Austria;20-39;;;10/14/24
Fully agree;;Fully agree;;Partly disagree;;Fully agree;;Fully agree;;Partly agree;;Fully agree;;Research;Iran;40-59;"Thanks for sharing this questionnaire. 
Good luck 
";niakan2@gmail.com;10/14/24
Fully agree;;Partly agree;;Neutral;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;"Artificial Intelligence; Information Technology; Research";Poland;40-59;;marek.sikora@polsl.pl;10/14/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Partly agree;sometimes the statistical solution shows you the most appropriate - but I agree that on 1 % of cases it is purely individual;Fully agree;it definitely needs a human in control !!!;"Medicine; Artificial Intelligence; Information Technology; Research";Canada;40-59;;;10/14/24
Fully agree;;Partly agree;;Partly disagree;;Neutral;;Fully agree;;Partly agree;;Partly agree;;"Information Technology; Research";Australia;40-59;;;10/14/24
Partly agree;Yes, but over-regulations could slow down unnecesarely and make Europe less competitive related with other areas.;Partly agree;Yes, right amount of regulation is a key factor;Neutral;I do not think that any democratic government use excesive technlogy, human factor is always important;Fully agree;Sure, publications are different to real projects. I think any researcher knows that;Partely agree;Too much information is not a problem, processing and making it usefull is our task;Fully agree;Sure, the idea of digital twin is the future;Fully agree;Again any researchers agree with this statement;"Artificial Intelligence; Research; Management";Spain;40-59;;jgr@ua.es;10/13/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Partely agree;;Partly agree;;Fully agree;;"Artificial Intelligence; Information Technology";United Kingdom;40-59;;njain1967@gmail.com;10/13/24
Fully agree;Yes, but also automation complacency or lack of vigilance on the physicians' part is also a problem.;Fully agree;What do we regulate? The question of regulation needs to be asked with much greater clarity.  The issue is not adequately understood.;Partly agree;Yes, but it is a complex question.  Research suggests that humans can perceive AI's responses as therapeutic.;Neutral;Too hard to answer the question. Metrics can be improved or re-prioritized.;Partely agree;There are two questions here. The volume of information can be controlled. False predictions are inevitable just as human errors are inevitable. But clearly too high a percentage of false predictions will sew distrust.;Partly agree;Can one attach a probability to context and circumstance or is too idiosyncratic? I think the more advanced systems accommodate circumstance rather well, albeit, not perfectly.;Fully agree;"Yes, that would be a problem. But a current problem with LLMs and other AI systems is that they lack a reflective capability. For example, they cannot assign a probability to the ""truth"" of their response. Put simply, what is the likelihood that a response/output is correct.";Research;USA;above 60;;david.kaufman@downstate.edu;10/13/24
Fully agree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";Netherlands;20-39;;;10/13/24
Fully agree;;Partly agree;;Partly agree;;Neutral;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Management";Austria;40-59;;;10/12/24
Fully disagree;;Partly agree;;Partly disagree;;Partly agree;;Partely agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research; Management";USA;40-59;;;10/12/24
Fully agree;Over-relieance always poses significant risks ;Partly agree;Excessive regulation could potentially stifle innovation by limiting the flexibility and freedom necessary for researchers and developers to experiment with novel AI technologies. However, some level of regulation is crucial to ensure safety, ethical standards, and societal well-being. The challenge lies in striking a balance between fostering innovation and protecting public interests;Fully agree;AI systems that replace human interaction in the patient-doctor relationship risk diminishing the empathy, understanding, and personal connection that are central to patient care. Actually this IS patient care.;Fully agree;This underscores the importance of aligning AI systems with comprehensive, patient-centered goals to ensure appropriate and beneficial outcomes.;Fully agree;When users are presented with too much irrelevant or incorrect data, it becomes difficult to make informed decisions, undermining confidence in the system's reliability - this is a standard assumption form Human-Computer Interaction Research!;Fully agree;Whilst statistical models are useful for identifying general patterns, they may not capture the nuances of unique patient conditions, preferences, or contextual factors that are critical for personalized care.;Fully agree;AI systems that evaluate themselves without independent oversight can lead to a lack of accountability and transparency, as there is no external mechanism to verify the correctness or fairness of their decisions.;"Medicine; Artificial Intelligence; Information Technology; Research; Management; Decision-Making";Canada;40-59;This is a very important study and should be published twofold: in the medial expert area and in the AI expert area - still there is a huge gap between those two groups. Maybe this study can bridge the gap!;;10/12/24
Fully agree;To a large extent, AI is like a black-box to medical professionals. Explainable AI has been promoted as a solution but clinicians are unfamiliar with how this works.;Partly disagree;The statement implies regulation is important but that there is a line beyond which it becomes restrictive to innovation. Since this line has not been defined, I prefer over-regulation than under-regulation.;Partly disagree;The question is unfair as it bundles compassion together with interaction. Both can occur (or not occur) with or without each other. Healthcare is a primarily human function that can benefit from the efficiencies brought about by automation and artificial intelligence. Some human interactions, if replaced by machines, can relieve strain for the workers. But all compassion is human.;Fully agree;;Fully agree;;Partly agree;Clinicians often base their decisions on the statistical analysis of evidence which they in turn apply to patients they encounter. But statistics is not perfect and clinicians must always correlate their findings with these studies.;Fully agree;"AI systems, while more powerful in search and analysis, may still make mistakes (""how many r's are there in 'strawberry'""). Their output should always be evaulated by human experts.";"Medicine; Management";Philippines;40-59;;alvin.marcelo@gmail.com;10/12/24
Fully agree;Not only that, errors propagate through the system. ;Fully agree;;Fully agree;It's a dangerous step. When machines are per eived to be humans and humans take on the roles of machines, disaster is the only outcome ;Fully agree;Numerous examples can be given, specifically for misclassification of diagnoses. ;Fully agree;;Fully agree;This can range from Ai hallucination to ecological fallacy. ;Fully agree;Another dangerous error, particularly with tools that depend on deep learning or improperly configured transfer learning can spell disaster. ;"Medicine; Artificial Intelligence; Information Technology; Research";New Zealand;40-59;If another version of this paper is planned, happy to contribute to the discussions if my contributions are considered. ;arinbasu@tuta.com;10/11/24
Fully agree;;Partly agree;regulators usually over-regulate so need their own counter-balancing by open discussion and public voting on proposed regulations.....;Fully agree;replace is the key word here.......partial replacement is ok, but full replacement without supervision is dicey! ;Partly agree;highly contingent on the details of metrics, their implementation, and the context of their applications in realistic situations of ethical challenge.....;Fully agree;common in many prematurely automated applications of technology - AI just amplifies the dangers....;Fully agree;;Fully agree;;"Artificial Intelligence; Information Technology; Research; Decision-Making";United States;above 60;very curious how results of this survey turn out!;kulikows@cs.rutgers.edu;10/11/24
Fully agree;The issue is how validation/verification should be undertaken in a rigorous way.  In medicine we do use treatments and procedures that are not 100% guaranteed to work.  Some trade-offs seem inevitable, depending on the setting.;Partly disagree;This issue has been debated in medical AI circles for 50 years!  Liability issues will likely always require that some kind of formal evaluation/validation will be required before routine use is appropriate, in part to help us to understand settings in which use is likely to be safe and those in which the validation of a system's advice or actions is problematic and may mandate more cautious use with close monitoring.;Partly agree;Full replacement is unlikely to be acceptable, in the near term at least, to either patients on physicians.  However, I ascribe to the notion that the physician, aided by AI, is likely to be more effective and acceptable than a physician who chooses not to use the technology.;Partly agree;"The challenge here is that ""overall patient outcomes"" may require years to assess, and we accordingly need to consider more short-term criteria to guide our assessment of the utility of an AI system.  Patient and physician satisfaction with the tool is only one such criterion.";Fully agree;The issue is not only what decisions are made by the AI system but how such assessments are offered to both patients and physicians.  Usability is one issue, but so it care in presenting guidance appropriately and conveying cautions that may be appropriate.;Fully agree;This shows the challenge in identifying the scope of a system's suitability for application, which is key element in proper evaluation and monitoring over time.;Fully agree;This seems clear until or unless formal studies and experience show essentially 100% suitability of a system's guidance, which is difficult to achieve (as per Sin 6);"Medicine; Artificial Intelligence; Research; Decision-Making";USA;above 60;;;10/11/24
Partly agree;In addition the nature and extent of the human AI collaboration needs to be mapped, responsibilities and competence of the user.  ;Fully agree;;Partly agree;Depends entirely on the task set for the AI. It can free time for tasks that require human interaction and compassion, when it employed correctly to task that can be automated/augmented.   ;Partly agree;;Fully agree;Use of AI requires also skills and understanding in its interpretation and use, which can reduce confusion and lack of trust.  ;Partly agree;Depends on the statistical models and how much they take into account population differences. ;Fully agree;;Research;Finland;20-39;;;10/11/24
Fully agree;;Partly agree;;Partly disagree;;Partly agree;;Partly disagree;;Partly agree;;Fully agree;;Research;Singapore;20-39;;woobrigitte@gmail.com;10/10/24
Fully agree;;Fully disagree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;Denmark;40-59;;boersen@plan.aau.dk;10/10/24
Fully agree;;Fully disagree;;Partly disagree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;USA;40-59;;joshvest@iu.edu;10/10/24
Fully agree;"Incidentally, this is also true of blind trust in humans, systems, policies, etc. ""I think therefore I am"", so if I'm not thinking for myself, I may as well not exist.";Partly agree;"I fully agree that this statement is true. I select partly agree, more to reflect the fact that taking big risks also comes with an expectancy of failure, and inevitably therefore, some degree of harm. This is why we need regulation. Who gets to decide what is ""excessive""? Those most likely to reap the benefits of progress or those most likely to experience harm from failures?";Neutral;This statement misses the point: 1) the consequences of loss of human patient-doctor relationship are much more serious, because we know that the human relationship itself has healing power, quite separately of biomedical interventions, so it's loss wouldharm health (see e.g. Kelley et al, 2014 10.1371/journal.pone.0094207) 2) I don't believe that loss of a human patient-doctor relationship will ever be a feasible or acceptable approach to running acute care services anyway (although this may be an issue in care for chronic conditions, where aspects of care can be more transactional and pressures on staff and funding may take a toll);Partly agree;Can this be more specific? If you mean metrics like profits for private providers, for example, then I completely agree. What other metrics may not align with overall patient outcomes?;Fully agree;Health psychology research (see e.g. the work of Ellen Langer) has revealed the power of informational or perceptual influences to change health outcomes. There is a very real element of self-fulfilling prophecy in healthcare. Positive AI predictions may be therapeutic in some cases, but may otherwise cause disappointment and reduce trust. Negative predictions may be actively damaging to health.;Fully agree;There is always uncertainty around predictions. How will that be communicated to avoid (damaging) determinism and self-fulfilling prophecy?;Fully agree;;"Medicine; Information Technology; Research";Netherlands;20-39;;d.n.neal@amsterdamumc.nl;10/10/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;;Sweden;above 60;;;10/10/24
Fully agree;;Partly disagree;;Partly agree;;Partly agree;;Fully agree;;Partly agree;;Partly disagree;;"Artificial Intelligence; Information Technology; Research; Management";Australia;above 60;;;10/10/24
Fully agree;Similar to Human Intelligence decisions being made that aren't adequately trained or using up to date information leading to poor decisions and potential harm. ;Partly agree;It's possible that well down regulation mitigates this and overall we want this to be a regulated tool within the health context. I agree that historically regulation tends to be too much or too little and it's inflexible so the practical manifestation of the sin is there - however - it's not a predetermined destiny of all regulation (in theory). ;Partly disagree;"Evidence out of North America seems to find the opposite; as long as the patient knows that an AI has been involved in the communication or drafting/decision making process with a final check by the human clinician, they seem to prefer the amount of perceived empathy from written AI communication than what comes from a human alone. UC San Diego seems to be doing a lot of work in this space. I acknowledge that it's possible to implement AI in such a way as to be dehumanising, however, there's evidence and reusable patterns that it's entirely avoidable. ";Fully agree;The AI is not holistically 'aware' and unless it has value-adding or meaningful metrics defined for it, it cannot maximise the achievement of patient outcomes. Probably needs ;Neutral;False predictions or forecasting is a major issue though it does depend on how the responses are phrased back, or if the AI model has guardrails around it to prevent it from fabricating/hallucinating in its responses and to more readily note when it doesn't know. Over-informing could be an issue in some circumstances though thus far the models seem to be responsive to shortening or lengthening responses based on prompts.;Partly agree;"For population or larger cohort decision making this is perfectly suitable and not an issue. Applying population level data to an individual has its flaws, however, until recently it's not as if that's not a staple of public policy and population health and overall health trends have improved. So, is some (large) data better than none? (such as a completely new patient receiving care with limited known/documented history) 
That said, individualised care is one of the key promises of big data and AI so that level of data should be factored in wherever possible. 
And there is a risk where a statistical finding is blindly or too heavily applied to an individual (such as noting penicillin allergies occur in 10% of the population, so on the law of averages every patient can have amoxicillin, and a patient with a true adverse reaction is prescribed amoxicillin). ";Fully agree;"I'd actually like to see more AI models deployed in adversarial pairs so that the primary AI system providing information is challenged by a variant model that has different weights or certain features altered to act as a double-check (lots to unpack there). 
Agree that something outside the AI system needs to monitoring it; which is exactly the same in non-AI situations to avoid misuse and corruption of power.";"Medicine; Information Technology; Management; Decision-Making";Australia;20-39;Good luck!;james.grant@health.qld.gov.au;10/10/24
Fully agree;"Over-reliance on human clinicians whose training is outdated and/or biased against the patients they see can lead to incorrect or inappropriate decision making that can cause harm to humans.
";Fully disagree;"Robust regulation could prevent unethical innovation, and limit the ability of researchers and developers to damage patients through experimentation and unnecessary risk-taking with new AI technologies.
";Neutral;Given the poor communication skills of some clinicians, some patients may find robotizing to be a pleasant and more helpful alternative.;Partly disagree;The patient outcomes metrics set by current non-AI systems don't necessarily align with what patients themselves actually prioritize, and AI-determined metrics may be an improvement over the current state.;Neutral;Clinicians that provide too much information or provide false predictions can lead to confusion and decreased trust in the medical profession. The notion that humans provide an optimal experience against which all other entities should be measured is a fantasy.;Partly agree;"Human clinicians that rely solely on statistical models without considering individual patient circumstances can lead to incorrect or inappropriate decision making.
";Fully agree;"However, human clinicians who rely solely on themselves for evaluation, without independent oversight, can lead to a lack of accountability and decreased transparency in decision making too.
";;USA;;;;10/10/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology";Australia ;20-39;;;10/10/24
Fully agree;;Partly agree;;Fully agree;;Neutral;;Partely agree;;Partly agree;;Partly agree;;Medicine;Australia;20-39;;;10/10/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology";USA;above 60;;dschloss39@gmail.com;10/9/24
Fully agree;;Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;United States;above 60;;RKOPPEL@SAS.UPENN.EDU;10/9/24
Fully agree;;Partly agree;;Partly disagree;;Fully agree;;Fully agree;;Fully disagree;;Fully disagree;;"Medicine; Artificial Intelligence";USA;40-59;;;10/9/24
Fully agree;"But medical data is often impossible to be flawless;  We can only use the most updated opinion according to latest research;  There is always a hidden risk even with human brain.";Partly agree;Government and professional bodies should encourage experiementing with AI;Partly disagree;"This same dilemma was seen when doctors first use computers in medical practice;  Early adopter will have adverse comments from patients, but later, patients get accustomed and even do not trust doctors who don't use a computer.";Fully agree;but the metrics are often multi-modal and hard to define;Neutral;The IBM Watson in oncology advisary is a good example to be witnessed;Partly agree;It can leave to the ultimate clinician's human decision;Fully agree;governance and rigorous scrutiny which is continually applied is of paramount importance;"Medicine; Information Technology; Management; Public Authority; Decision-Making";China;above 60;;cp@cpwong.com;10/9/24
Fully agree;Yes, we have to educate the users to critically reflect the suggestions. ;Fully agree;;Fully agree;Yes, they can. We have to provide solutions that offer more quality-time for the patient-doctor relationship. And we have to educate physician that they should use the time for this. ;Neutral;Sorry, I do not understand the question.;Partely agree;Too much information might be OK, because the user is activated to analyse what is relevant to his question. False predictions SHOULD lead to decreased trust in the technology;Partly agree;Yes, that is exactly the task of the physician to take the individual patient circumstances into account and to KNOW that the model is just a statistical one. ;Neutral;;Research;Germany;40-59;The survey took me much longer than 4 minutes.;petra.knaup@med.uni-heidelberg.de;10/9/24
Fully agree;Same as over-reliance on human experts.;Fully agree;Medical imaging interpretation AI-based applications should  be available to patients as a 'first opinion' without much restrictions.;Fully disagree;Some AI systems are capable of empathizing much better than humans...;Neutral;;Fully disagree;Today, there is almost no informed consent processes as required by most patient rights bills, so any addition from AI cannot generate too much information, since you can ask the AI to present it in any extent desired.;Fully agree;Indeed, and what's needed is case-based reasoning to complement statistical models and get us a bit closer to personalized medicine. The issue is that the 'case' does not exist in a form that could make case-based reasoning truly powerful and that's due to data fragmentation and lack of independent lifetime health record.;Partly disagree;What's needed is to follow the neuro-symbolic approach to AI, where neural networks are complemented by symbolic reasoning methods that allow explanation and tracing.;Research;Israel;above 60;Thanks for this important survey!;amnon.shvo@gmail.com;10/9/24
Neutral;This is emergent technology - overall very likely benefit but inevitable downsides.;Fully agree;We risk demonising.  We need open science. ;Partly disagree;We have to select where it can save time, reduce routine questioning, but embrace as we have gaps in quality in medical care. ;Partly agree;A risk;Partly disagree;"This is a weak statement.  ""Too much information"" + ""False predictions"" can be part of all interactive processes, including the delivery of clinical care.  Who of us don't get calls wrong in clinical care. ";Partly disagree;Most evidence-based medicine applies large study outcomes or their meta-analyses to individuals.  With the exception of some immunotherapies - most medicine is on this basis not personalised.;Partly agree;Oversight is needed with all processes.  However, much can be provided internally.  Most or our safety signals are provided in this way. ;"Medicine; Information Technology; Research";England;above 60;"It would be good to see these statements in a more nuanced form.  
A survey like this might better draw comparisons with ""real"" current clinical practice, which is regrettably not error free. Maybe exploring whether the types of error made in current clinical care might be reduced by AI.  ";simon.delusignan@phc.ox.ac.uk;10/9/24
Fully agree;;Partly agree;As far as the technology is applied in practice, strict regulation is needed. This is particularly true for applications targeting general audience, such as ChatGPT;Partly disagree;"it is a matter of design and implementation; on the contrary it may lead to save time and improve patients/doctor relationships";Fully agree;;Fully agree;;Fully agree;;Partly agree;We use all day automated systems that do not have independent oversight. It is the specific application/device that generates the risk.;"Medicine; Artificial Intelligence; Information Technology; Research";Italy;above 60;;riccardo.bellazzi@unipv.it;10/9/24
Fully agree;The seduction of the technology ;Neutral;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Decision-Making";Australia;above 60;This is an appropriate survey ;drterryhannan@gmail.com;10/9/24
Fully agree;Trusting AI 100% is no accepted because it might commit a mistake that only qualified human being can notice.;Fully agree;NO excessive regulation and never let technology control humans. ;Fully agree;Patient-physician relation is important unless it is the choice of the patient to seek advice for robots, chats etc. with full understanding that it is their responsibility. ;Fully agree;;Fully agree;This is especially when you have half educated doctors and not educated patients.;Fully agree;;Fully agree;;Information Technology;Jordan;above 60;AI is very good, but in healthcare and medicine it has very very very long way to go. ;shorbajin@gmail.com;10/8/24
Fully agree;;Neutral;this is a hrad question;Neutral;will not happen;Fully agree;;Fully agree;;Neutral;standard medicien is doing this for many years;Fully agree;;"Medicine; Information Technology; Research; Management; Decision-Making";USA;40-59;;;10/8/24
Fully agree;;Fully agree;;Neutral;;Partly disagree;;Fully agree;;Partly agree;;Partly agree;;"Information Technology; Research";USA;above 60;;;10/8/24
Fully agree;;Partly disagree;ai is such a booming field, I don't think even excessive regulation will stifle innovation significantly ;Partly agree;;Fully agree;;Partely agree;I think it contributes to misinformation more than distrust;Fully agree;;Partly agree;;;USA;20-39;;;10/8/24
Fully agree;The seduction of the technology ;Neutral;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Decision-Making";Australian ;above 60;This is an appropriate survey ;drterryhannan@gmail.com;10/8/24
Fully agree;The seduction of the technology ;Neutral;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Decision-Making";Australian ;above 60;This is an appropriate survey ;drterryhannan@gmail.com;10/8/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Partely agree;Agree fully on false predictions, partly agree on too much information;Fully agree;;Fully agree;;"Information Technology; Research";United States;20-39;;sneddybrojoe@gmail.com;10/7/24
Partly agree;Currently true, but I expect this to switch to failure to heed AI decisions can lead to patient harm within the next 5 years.;Partly agree;on the other hand researchers taking unnecessary risks could lead to significant harm.;Partly disagree;it looks like the AI is already better at empathy and the many clinicians.;Partly agree;this will be hard to judge since different patients can  prioritize different outcomes. Some patients may want life at all costs, others may decide on a shorter life with less side effects and complications.;Partely agree;too much information (assuming it is correct) and false predictions seem like 2 entirely different things.;Partly agree;"this depends in part on whether the ""individual circumstances"" include data that the AI did not have access to. if the AI has the same data as the other decider, then I'm not sure what the other decider is basing their decision on.";Partly agree;currently true, but I expect within 10 years that the AI will be better than anyone doing any sort of oversight is capable of.;"Artificial Intelligence; Information Technology; Research";USA;above 60;This is an interesting approach, but very time limited. the capabilities of the AI are increasing so fast, that I fear that anything that is true today, will not be true in 3-5 years. I think these concepts are important at this exact instant, though.;dean.sittig@gmail.com;10/7/24
Fully agree;;Fully agree;;Partly disagree;It depends on how the responsible physicians (assuming there are some) make use of it.;Partly disagree;There are many intermediate targets;Fully agree;;Partly agree;Sometimes we don't know enough to do better.;Fully agree;;"Medicine; Information Technology; Decision-Making";USA;above 60;;ciminoj@uab.edu;10/7/24
Fully agree;;Fully agree;;Fully disagree;In the contrary AI could support repetitive tedious actions , releasing time to value interaction ;Fully agree;;Fully agree;;Fully agree;With more data about individuals we are going to have challenges in having real reference baselines, then the problem of n=1, probably prevalence and incidence models need to be analyze in the context of network ;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";USA;40-59;;jff4001@med.cornell.edu;10/7/24
Fully agree;Human judgement is still more reliable to check for any errors.;Fully agree;  Some regulation is needed to protect the technology that could be developed to harm us, but for innovation we do need some freedom. ;Partly agree;IF AI systems can progress to the level to embed compassion, there is some possibility of providing support, otherwise it will dehumanize D-P interaction.;Fully agree;;Fully agree;Over information leads to lack of utility. ;Fully agree;Individuals are not a statistic;Fully agree;Accountability and transparency are the cornerstones of building trust in AI systems;"Medicine; Research; Decision-Making";USA;above 60;I am a researcher in Medicine and healthcare, who works at the interface of human-AI interface. Without concurrent focus on the development of human mind, the progress in AI will be a problem to humankind.;;10/7/24
Fully agree;;Fully agree;;Partly disagree;it depends on the application and the preference of the patient ;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Research;USA;above 60;;;10/7/24
Fully agree;;Fully agree;;Partly disagree;;Partly agree;;Partely agree;;Partly agree;;Fully agree;;"Information Technology; Decision-Making";USA;above 60;;;10/7/24
Fully agree;;Fully agree;;Neutral;We've seen at least anecdotal evidence that some AI systems actually provide more communication and more perceived empathy.;Neutral;Too broad a statement -- patient outcomes are paramount, but there could be cases where other priorities must be recognized -- such as allocating highly limited resources to provide best care for the greatest number.  Second, this statement depends on a definition of patient outcomes: some patients will prefer longest life, others least suffering, others greatest ability to interact with their families, etc.;Fully agree;;Partly agree;If the AI is forthcoming and states exactly what it is concluding and the basis for that, then it is reasonable to make full use of statistical optimization.  For example, a statistical model may give an answer that provides statistically greatest chances of life preservation, but the process and procedures involved may not be acceptable to some patients.  If the AI states this -- as physicians should do whenever entering into shared decision making with patients -- the patient can make the best choice for themselves.;Partly agree;;"Medicine; Artificial Intelligence; Information Technology";USA;above 60;;;10/7/24
Fully agree;;Partly agree;"What is excessive regulation to some developers would not seem excessive to users of AI algorithms. So I can not fully agree with Sin 2 without some definition of ""excessive regulation"". ";Fully agree;;Partly agree;Too many fuzzy words in this Sin. What metrics? What outcomes? ;Fully agree;Duh.;Fully agree;AI systems cannot have all important information about a patient available digitally. The clinician will always know things that the computer will not know, some of which may be important to clinician-patient decision-making and patients' preferred outcomes. ;Fully agree;Again, duh!;"Medicine; Information Technology; Research; Management; Decision-Making";USA;above 60;;;10/7/24
Fully agree;;Partly disagree;"I am not sure what is ""excessive regulations"" means. How to you measure what is excessive in uncharted waters. Is this controlling profit oriented commercial concerns? Is this not requiring well established practices in other engineering disciplines as uncertainty quantification and quality control?";Partly agree;;Fully agree;;Fully agree;;Fully agree;"Please see: https://ebooks.iospress.nl/pdf/doi/10.3233/SHTI231113; https://pubmed.ncbi.nlm.nih.gov/35898853/; https://pubmed.ncbi.nlm.nih.gov/39019301/.";Fully agree;See: https://pubmed.ncbi.nlm.nih.gov/39019301/.;"Artificial Intelligence; Information Technology; Research";USA;above 60;Very important work.;JULIO.FACELLI@UTAH.EDU;10/7/24
Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Information Technology; Decision-Making";USA;above 60;"Let's be clear. The ethics of ""AI"" used in any literature and for making any decision, is akin to the ethics of ""word processing"" or ""spell checking"" (dare I even say ""fact checking?""). That is, the issues of readability, actionability, preference, standards, values and etc. are all applicable regardless of the tools involved in the derivation of the advice. All ""AI"" really does is allow a sorting of greater quantities of information and makes that quantity of information more relevant to the individual and their condition(s). As of now, in medicine, it is the channel between the ""provider"" and the ""patient"" where the decision is made. If the ""provider"" becomes the ""mouthpiece"" for computational advice and advocates only what he or she is told by ""AI"", then shame on  them. Unfortunately, no amount of regulation or ""ten commandmentizing"" is going to legislate against this bad behavior. Unlike, Greenes' 10 Commandments for Medical Decisionmaking, these directives are more punitive than instructive.  ";Eric.silfen@medtechanalytics.com;10/7/24
Fully agree;;Partly agree;"agree but ""excessive"" is in the eye of the beholder. I believe some regulation is definitely called for.";Fully agree;i know that LLM responses have gotten higher ratings for empathy than human docs, but transparency is key, and once the patient knows it's a bot reassuring them, I suspect it's less satisfying.;Neutral;true, but not unique to AI. feels less salient than the others.;Fully agree;;Partly agree;agree, but as with 4, not as unique to AI.;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research";USA;40-59;;;10/7/24
Partly disagree;"The concerns related to Blind Trust vary widely depending on the strategies available for validation and verification, including how these aspects would be reported.  It would also be helpful to consider how one might deteremin ""incorrect or inappropriate"" in a health care system characterized by multiple disciplines, whose perspectives alone might lead some to conclude that the decisions made by disciplines different than their own are incorrect or inappropriate, completely unrelated to the AI recommendation";Fully agree;"I don't get  what the ""no-guts, no glory"" phrase is intended to mean, but I do agree with the sentiment that over-regulation is limiting and risks innovation";Fully disagree;"This is too value-ladened with assumptions that 1) the patient-doctor relationship is the only important one; 2) the patient-doctor relationship is characterized by empathy (aspirational but not always true) and 3) patient satisfactions depends solely on the patient-doctor relationship (clearly not true)- . the ""Robotization and Dehumanization' phrase is catchy and compelling but does not match the content of the subsequent statement";Partly disagree;The phrase is good and important , but belies the complexity of the tradeoffs between focusing on individual patient outcomes at the expense of public health or population goals - ;Partely agree;I believe that this 'sin' targets clinician burden -- if so I think it is correct and relevant;Fully disagree;this is not related to AI alone;Neutral;The idea of 'independent oversight ' does not insure accountability and reduction of bias - also not sure how the idea of evaluation relates to transparency -- consider that the 'independent oversight' may bring along its own biases;"Information Technology; Research; Public Authority";USA;above 60;"I find the use of the word ""Sins"" to be sort of catchy and casual, and does not convey the serious nature of the concerns that I believe are leading to this exploration.  Also it seems that these items focus only on the use of AI for care recommendations (diagnosis, management) and do not address the development and training af AI systems and seems to not attend to other applications of AI such as robotics, implantable devices  and image analysis";pattifbrennan@gmail.com;10/7/24
Fully agree;;Partly agree;;Neutral;I don't believe it is the technology that will decrease compassion. How humans act when using technology might change clinician and patient interactions.;Partly agree;;Fully agree;;Neutral;Depends on the goal of the AI system.;Partly agree;I believe it would depend on how that evaluation takes place. Is the evaluation scientific sound? Generalizable?;"Medicine; Artificial Intelligence; Research";USA;40-59;;;10/7/24
Partly agree;Balanced evidence should support every claim.  In this case good advice may improve clinical decision making.;Partly agree;Safety is paramount.  However the world need is great and when some areas of the world lack basic care access, we need to understand that perfect can be the enemy of good.;Partly agree;It is unclear what leads to patient satisfaction.  More research is needed.;Partly agree;Again balanced evidence should support any claim.  Specific vs Overall patient outcomes is poorly defined.;Partely agree;Again balanced evidence should support any claim.  It depends on error rates.  Bates et all stated the rate of medication errors in 36 healthcare organizations was 11.2%.  If AIs are less than perfect but better than doctors, can you really fault them or instead should be work asymptotically toward improvement.;Partly agree;Again balanced evidence should support any claim.   LLMs can take into account patient preferences and marginal utilities if they are presented to the AI.;Partly agree;i agree that independent evaluation is important, but as these models learn, they would need to be reveiwed often and at great cost to do this perfectly.  ;"Medicine; Artificial Intelligence; Research";USA;above 60;"Please see
Franklin G, Stephens R, Piracha M, Tiosano S, Lehouillier F, Koppel R, Elkin PL. The Sociodemographic Biases in Machine Learning Algorithms: A Biomedical Informatics Perspective. Life (Basel). 2024 May 21;14(6):652. doi: 10.3390/life14060652. PMID: 38929638; PMCID: PMC11204917.";elkinp@buffalo.edu;10/7/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Partly agree;;Neutral;;"Artificial Intelligence; Information Technology; Decision-Making";USA;40-59;;;10/7/24
Fully agree;;Partly agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence";USA;20-39;;blr2152@cumc.columbia.edu;10/7/24
Fully agree;;Partly disagree;;Partly disagree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;"Artificial Intelligence; Research";USA ;20-39;;ab3886@cumc.columbia.edu;10/7/24
Partly agree;We should be able to trust them when they have proven to be better than us, even if not perfect;Fully agree;True progress will shake society and requires a new way of organizing things. Over-regulating may slow down the process, all the more as when we consider the international race.;Neutral;AI systems can be more patients and show empathy consistently, even though they do not replace human interactions.;Partly agree;Alignment issue is an important research topic.;Fully agree;People should be educated or isolated.;Partly agree;This is a deeply ethical question: society vs individuals.;Neutral;Caution to adversarial attacks. But another validated AI that judges other AIs does not seem a big issue to me.;"Artificial Intelligence; Information Technology";USA;20-39;;;10/7/24
Fully agree;;Neutral;;Fully disagree;;Neutral;;Neutral;;Fully disagree;;Partly agree;;"Artificial Intelligence; Decision-Making";USA;20-39;;pkhorasa@asu.edu;10/7/24
Fully agree;;Partly disagree;Innovation should be encouraged, but necessary regulation is critical for safe application of AI in healthcare and the long-term development of the field. ;Fully agree;;Fully agree;;Partely agree;;Fully agree;;Fully agree;;"Medicine; Artificial Intelligence; Information Technology; Research; Decision-Making";USA;40-59;;;10/7/24
Fully agree;;Partly agree;;Neutral;;Fully agree;;Partely agree;;Fully agree;;Partly agree;;Artificial Intelligence;India;20-39;;tshekhaw@asu.edu;10/7/24
Partly agree;there should be regulations and norms and rules to apply them;Neutral;there is the Option of regulatory sandboxes;Partly agree;there shouln’t be systems which fully replace human interaction here;Partly agree;I would not trust this kind of systems;Neutral;there must be a refining of the output or at least awareness of this problem;Partly agree;"also if it considering these circumstances, therefore in this cases, there have to be a human in the loop
";Fully agree;there is a need for external, interdisciplinay specialists;"Artificial Intelligence; Research";Germany;above 60;;;9/25/24
Fully agree;;Partly agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;Fully agree;;"Information Technology; Research";Austria;40-59;;johannes.kropf@4brains.at;9/25/24
Fully agree;;Fully agree;;Partly disagree;Many doctors are not good at showing empathy. It is not hard to design AI that interacts in an empathetic way, perhaps easier than to train a human who is otherwise a good doctor.;Fully agree;;Partely agree;;Partly agree;;Partly agree;;"Artificial Intelligence; Information Technology; Research";UK;40-59;;;9/24/24
Fully agree;;Partly agree;;Fully agree;;Partly agree;Probably true in multi-morbidities, but for common cases of single aetiology there should be good alignment.;Fully agree;;Fully agree;;Fully agree;;"Medicine; Research";France;;;kozlakidisz@who.int;9/24/24
Fully agree;;Partly agree;;Partly agree;;Partly agree;;Partely agree;;Fully agree;;Partly agree;;"Artificial Intelligence; Information Technology; Research";Greece;;;;9/23/24
Fully agree;this in not only about AI systems. everything should be validated and tested;Fully agree;EU regulates too much;Partly disagree;Robots never have a bad mood and can always be friendly and empathetic compared to humans after a difficult working day or due to private problems.;Fully agree;;Partely agree;"there is not ""too much"" information in my opinion. the question is how this information is presented";Fully agree;it is possible to win a lottery, but with a high probability, it won't be me;Partly agree;a proper algorithm can be better than humans;"Artificial Intelligence; Information Technology; Research";USA;;;;9/23/24
Fully agree;;Partly disagree;;Partly disagree;;Partly agree;;Neutral;"This question is not well designed. There is an enormous difference between ""too much information"" versus ""false predictions"". One could have ""too much information"" from a system that's near perfect.";Partly disagree;;Partly disagree;;"Medicine; Artificial Intelligence; Research; Decision-Making";USA;;"In the Us, existing regulation by the FDA is mostly sufficient. The problem are legal loopholes, like ""Lab Developed Tests"" (LDTs) that allow vendors and practitioners to circumvent FDA regulation.";th.j.fuchs@gmail.com;9/23/24
Fully agree;absolutely agree, because AI systems, while regarded powerful, can still exhibit biases, errors, or lack the context necessary for making nuanced decisions;Neutral;Careful, I would position my opinion somewhere in the middle. While excessive regulation can indeed stifle innovation and limit flexibility needed for researchers and developers, a complete lack of regulation could lead to significant ethical, safety, and societal risks. Striking the right balance between fostering innovation and ensuring responsible development is crucial. This is a hard question.;Partly agree; Here I would lean towards agreeing with this statement -but not fully. While AI systems can significantly enhance healthcare by improving diagnostic accuracy, efficiency, and decision support, they may lack the capacity for human empathy, which is a critical component of the patient-doctor relationship.;Fully agree;Fully agree. When AI systems prioritize metrics that are not aligned with overall patient outcomes, this can lead to suboptimal or even harmful decision-making in healthcare. AI systems that focus on specific metrics, such as cost reduction or operational efficiency, without considering broader patient-centered outcomes, may overlook critical factors like long-term health, quality of life, or patient satisfaction. ;Fully agree;More than fully agree. AI systems that overwhelm users with excessive information or generate false predictions can indeed cause much much confusion and erode trust in the technology. When users, particularly in high-stakes fields like healthcare or finance, are faced with an overload of data or inaccurate outputs, it becomes difficult to discern what is reliable, which can lead to poor decision-making. Trust in AI systems is contingent on their ability to provide clear, accurate, and actionable insights, making the careful design of these systems—both in terms of information delivery and prediction quality—critical for user confidence and acceptance.;Fully agree;yeah, relying solely on statistical models without considering individual patient circumstances can indeed lead to incorrect or inappropriate decision-making in AI systems. Statistical models are based on aggregated data and general trends, which may not account for the unique factors that influence an individual's health—such as genetics, lifestyle, environment, and medical history. Ignoring these personalized factors can result in recommendations that are ineffective or even harmful for specific patients. Therefore, it's essential for AI systems, especially in healthcare, to incorporate individual patient data to provide accurate, tailored, and appropriate guidance.;Fully agree;Yes, I think when AI systems evaluate themselves without any independent oversight, it can indeed lead to a lack of accountability and decreased transparency in decision-making processes. Independent oversight is and was always essential to detect biases, errors, or unintended consequences that the AI system itself may not recognize (therefore we need more than one opinion). Without external evaluation, there is a risk that the AI could perpetuate its own flaws or make decisions that are not aligned with ethical standards or societal values. Transparency and accountability are crucial for building trust in AI technologies, and independent oversight helps ensure that AI systems operate fairly, responsibly, and effectively.;"Artificial Intelligence; Information Technology; Research";Canada;;;;9/20/24
Fully agree;Good example is AI for coding;Partly agree;;Partly agree;Kind of, but if this decreases the waiting time, it would still be a big benefit ;Fully agree;;Partely agree;Like Chat GPT 4 which talks A LOT;Partly agree;But they can point in the direction ;Fully agree;Someone has to filter out the halicunations;Information Technology;Austria;;;;7/17/24